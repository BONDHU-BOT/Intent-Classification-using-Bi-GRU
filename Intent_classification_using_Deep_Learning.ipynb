{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Dark-Sied/Intent_Classification/blob/master/Intent_classification_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intent Classification using Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "a_WypuUXi92e",
    "outputId": "133d026e-4236-4ff6-f21d-739bfb9640db"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, GRU, LSTM, Bidirectional, Embedding, Dropout\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset link: https://raw.githubusercontent.com/PolyAI-LDN/task-specific-datasets/master/banking_data/train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Intent = \"category\"\n",
    "Sentence = \"text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LE6wywJrN2ih"
   },
   "outputs": [],
   "source": [
    "def load_dataset(filename, Sentence, Intent):\n",
    "  df = pd.read_csv(filename, names = [Sentence, Intent])\n",
    "  intent = df[Intent]\n",
    "  unique_intent = list(set(intent))\n",
    "  sentences = list(df[Sentence])\n",
    "  \n",
    "  return (df, intent, unique_intent, sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "tF0FQA7gjOCX",
    "outputId": "c609b42a-05da-49f5-8d11-bd670210f635"
   },
   "outputs": [],
   "source": [
    "df, intent, unique_intent, sentences = load_dataset(\"Dataset.csv\", \"text\", \"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text      category\n",
      "0                                               text      category\n",
      "1                     I am still waiting on my card?  card_arrival\n",
      "2  What can I do if my card still hasn't arrived ...  card_arrival\n",
      "3  I have been waiting over a week. Is the card s...  card_arrival\n",
      "4  Can I track my card while it is in the process...  card_arrival\n",
      "5  How do I know if I will get my card, or if it ...  card_arrival\n",
      "6                  When did you send me my new card?  card_arrival\n",
      "7       Do you have info about the card on delivery?  card_arrival\n",
      "8  What do I do if I still have not received my n...  card_arrival\n",
      "9       Does the package with my card have tracking?  card_arrival\n"
     ]
    }
   ],
   "source": [
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='category', ylabel='count'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import tkinter\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "sns.countplot(x=Intent, data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "O8LLUZlokg0S",
    "outputId": "c15c21dc-2ef2-43b7-b4af-e7ee9e014091"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text', 'I am still waiting on my card?', \"What can I do if my card still hasn't arrived after 2 weeks?\", 'I have been waiting over a week. Is the card still coming?', 'Can I track my card while it is in the process of delivery?']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "MhrziINPGHbW",
    "outputId": "0861af1b-4b82-4c92-b8f4-b6b57bb3e380"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/shiningflash/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/shiningflash/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OmNLu2YSXePb"
   },
   "outputs": [],
   "source": [
    "#define stemmer\n",
    "stemmer = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j-7q3iG5PKYI"
   },
   "outputs": [],
   "source": [
    "def cleaning(sentences):\n",
    "  words = []\n",
    "  for s in sentences:\n",
    "    clean = re.sub(r'[^ a-z A-Z 0-9]', \" \", s)\n",
    "    w = word_tokenize(clean)\n",
    "    words.append([i.lower() for i in w])\n",
    "    \n",
    "  return words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "p1j2GJgDG6qj",
    "outputId": "c7232a8e-6833-4a1d-e71a-4bc7014084a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10004\n",
      "[['text'], ['i', 'am', 'still', 'waiting', 'on', 'my', 'card']]\n"
     ]
    }
   ],
   "source": [
    "cleaned_words = cleaning(sentences)\n",
    "print(len(cleaned_words))\n",
    "print(cleaned_words[:2])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Texts Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SJCQ_YhBJW7t"
   },
   "outputs": [],
   "source": [
    "def create_tokenizer(words, filters = '!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~'):\n",
    "  token = Tokenizer(filters = filters)\n",
    "  token.fit_on_texts(words)\n",
    "  return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QJhdIJC5Q3Q6"
   },
   "outputs": [],
   "source": [
    "def max_length(words):\n",
    "  return(len(max(words, key = len)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JWjxPGsZZJNX",
    "outputId": "b02c8f6b-d0df-4e90-fa3a-2ff730c88300"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size = 2343 and Maximum length = 84\n"
     ]
    }
   ],
   "source": [
    "word_tokenizer = create_tokenizer(cleaned_words)\n",
    "vocab_size = len(word_tokenizer.word_index) + 1\n",
    "max_length = max_length(cleaned_words)\n",
    "\n",
    "print(\"Vocab Size = %d and Maximum length = %d\" % (vocab_size, max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D0TXu2xsR8jq"
   },
   "outputs": [],
   "source": [
    "def encoding_doc(token, words):\n",
    "  return(token.texts_to_sequences(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dE92Hk1Va--H"
   },
   "outputs": [],
   "source": [
    "encoded_doc = encoding_doc(word_tokenizer, cleaned_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fyOzLEboc4LZ"
   },
   "outputs": [],
   "source": [
    "def padding_doc(encoded_doc, max_length):\n",
    "  return(pad_sequences(encoded_doc, maxlen = max_length, padding = \"post\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WdejoJrlc-tc"
   },
   "outputs": [],
   "source": [
    "padded_doc = padding_doc(encoded_doc, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "gDgTCS2KdI2p",
    "outputId": "ac5332cd-0a0f-4311-8db4-22df92728d90"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1481,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0],\n",
       "       [   1,   50,   64,  208,   30,    2,    6,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0],\n",
       "       [  13,    8,    1,   10,   56,    2,    6,   64,  121,   11,  275,\n",
       "         161,  453,  304,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0],\n",
       "       [   1,   27,   52,  208,  305,    4,  240,    7,    5,    6,   64,\n",
       "         454,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0],\n",
       "       [   8,    1,  361,    2,    6,  183,    9,    7,   28,    5,  216,\n",
       "          38,  362,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_doc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3eaSIDi0dNf1",
    "outputId": "4ab6b6dd-ffa4-4061-9e9d-7a01decfa837"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of padded docs =  (10004, 84)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of padded docs = \",padded_doc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X0rXzenSpgFR"
   },
   "outputs": [],
   "source": [
    "#tokenizer with filter changed\n",
    "output_tokenizer = create_tokenizer(unique_intent, filters = '!\"#$%&()*+,-/:;<=>?@[\\]^`{|}~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "yNHQtkszskxr",
    "outputId": "f5babc01-89e3-4392-e8e6-c9f257de3d07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exchange_rate': 1,\n",
       " 'contactless_not_working': 2,\n",
       " 'declined_cash_withdrawal': 3,\n",
       " 'card_arrival': 4,\n",
       " 'card_payment_fee_charged': 5,\n",
       " 'wrong_exchange_rate_for_cash_withdrawal': 6,\n",
       " 'why_verify_identity': 7,\n",
       " 'passcode_forgotten': 8,\n",
       " 'cash_withdrawal_charge': 9,\n",
       " 'top_up_limits': 10,\n",
       " 'balance_not_updated_after_cheque_or_cash_deposit': 11,\n",
       " 'transfer_timing': 12,\n",
       " 'balance_not_updated_after_bank_transfer': 13,\n",
       " 'card_payment_not_recognised': 14,\n",
       " 'failed_transfer': 15,\n",
       " 'transaction_charged_twice': 16,\n",
       " 'order_physical_card': 17,\n",
       " 'wrong_amount_of_cash_received': 18,\n",
       " 'card_not_working': 19,\n",
       " 'pending_transfer': 20,\n",
       " 'direct_debit_payment_not_recognised': 21,\n",
       " 'getting_virtual_card': 22,\n",
       " 'edit_personal_details': 23,\n",
       " 'compromised_card': 24,\n",
       " 'transfer_fee_charged': 25,\n",
       " 'verify_my_identity': 26,\n",
       " 'country_support': 27,\n",
       " 'top_up_by_card_charge': 28,\n",
       " 'refund_not_showing_up': 29,\n",
       " 'cancel_transfer': 30,\n",
       " 'get_physical_card': 31,\n",
       " 'receiving_money': 32,\n",
       " 'card_swallowed': 33,\n",
       " 'age_limit': 34,\n",
       " 'extra_charge_on_statement': 35,\n",
       " 'disposable_card_limits': 36,\n",
       " 'change_pin': 37,\n",
       " 'declined_card_payment': 38,\n",
       " 'card_delivery_estimate': 39,\n",
       " 'reverted_card_payment': 40,\n",
       " 'card_payment_wrong_exchange_rate': 41,\n",
       " 'get_disposable_virtual_card': 42,\n",
       " 'terminate_account': 43,\n",
       " 'pending_cash_withdrawal': 44,\n",
       " 'top_up_reverted': 45,\n",
       " 'transfer_not_received_by_recipient': 46,\n",
       " 'supported_cards_and_currencies': 47,\n",
       " 'lost_or_stolen_phone': 48,\n",
       " 'category': 49,\n",
       " 'exchange_via_app': 50,\n",
       " 'atm_support': 51,\n",
       " 'pending_card_payment': 52,\n",
       " 'exchange_charge': 53,\n",
       " 'lost_or_stolen_card': 54,\n",
       " 'unable_to_verify_identity': 55,\n",
       " 'getting_spare_card': 56,\n",
       " 'virtual_card_not_working': 57,\n",
       " 'cash_withdrawal_not_recognised': 58,\n",
       " 'declined_transfer': 59,\n",
       " 'top_up_by_cash_or_cheque': 60,\n",
       " 'apple_pay_or_google_pay': 61,\n",
       " 'visa_or_mastercard': 62,\n",
       " 'beneficiary_not_allowed': 63,\n",
       " 'activate_my_card': 64,\n",
       " 'pending_top_up': 65,\n",
       " 'transfer_into_account': 66,\n",
       " 'card_about_to_expire': 67,\n",
       " 'top_up_failed': 68,\n",
       " 'pin_blocked': 69,\n",
       " 'verify_top_up': 70,\n",
       " 'request_refund': 71,\n",
       " 'card_linking': 72,\n",
       " 'automatic_top_up': 73,\n",
       " 'top_up_by_bank_transfer_charge': 74,\n",
       " 'verify_source_of_funds': 75,\n",
       " 'topping_up_by_card': 76,\n",
       " 'card_acceptance': 77,\n",
       " 'fiat_currency_support': 78}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7OOx9qdBto1-"
   },
   "outputs": [],
   "source": [
    "encoded_output = encoding_doc(output_tokenizer, intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0_5Lv5PiyG-z"
   },
   "outputs": [],
   "source": [
    "encoded_output = np.array(encoded_output).reshape(len(encoded_output), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dpM86WrVQlx5",
    "outputId": "71ff52a6-b3d0-4b5c-850d-5dc0a56c8aa9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10004, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rD3QN-RPzfet"
   },
   "outputs": [],
   "source": [
    "def one_hot(encode):\n",
    "  o = OneHotEncoder(sparse = False)\n",
    "  return(o.fit_transform(encode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z6wP_Xed7RNR"
   },
   "outputs": [],
   "source": [
    "output_one_hot = one_hot(encoded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "A6HVslLTHgOM",
    "outputId": "752962df-02d8-409b-fb8f-adb06227161d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10004, 78)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EqABUESD7xi9"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h8P4HTz6A4E-"
   },
   "outputs": [],
   "source": [
    "train_X, val_X, train_Y, val_Y = train_test_split(padded_doc, output_one_hot, shuffle = True, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "7E0uhC2OCtTx",
    "outputId": "6ce0e215-aa3f-43f1-ba5a-0b584b25a35c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_X = (8003, 84) and train_Y = (8003, 78)\n",
      "Shape of val_X = (2001, 84) and val_Y = (2001, 78)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of train_X = %s and train_Y = %s\" % (train_X.shape, train_Y.shape))\n",
    "print(\"Shape of val_X = %s and val_Y = %s\" % (val_X.shape, val_Y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Bidirectional GRU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e5BU_x74DNEb"
   },
   "outputs": [],
   "source": [
    "def create_model(vocab_size, max_length):\n",
    "  model = Sequential()\n",
    "  model.add(Embedding(vocab_size, 128, input_length = max_length, trainable = False))\n",
    "  model.add(Bidirectional(GRU(128)))\n",
    "  model.add(Dense(32, activation = \"relu\"))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Dense(78, activation = \"softmax\"))\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "f-NvE0P7MFCe",
    "outputId": "8f07056b-579e-4c15-e1af-bdfa8f681e79",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 84, 128)           299904    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 256)               198144    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 78)                2574      \n",
      "=================================================================\n",
      "Total params: 508,846\n",
      "Trainable params: 208,942\n",
      "Non-trainable params: 299,904\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(vocab_size, max_length)\n",
    "\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 6834
    },
    "colab_type": "code",
    "id": "_r-dxm2sMQ-d",
    "outputId": "3c37b4f8-fc4e-4c82-ab46-2aa1d8b47ffd"
   },
   "outputs": [],
   "source": [
    "filename = 'model.h5'\n",
    "checkpoint = ModelCheckpoint(filename,\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 4.3465 - accuracy: 0.0151\n",
      "Epoch 00001: val_loss improved from inf to 4.32916, saving model to model.h5\n",
      "251/251 [==============================] - 19s 76ms/step - loss: 4.3465 - accuracy: 0.0151 - val_loss: 4.3292 - val_accuracy: 0.0165\n",
      "Epoch 2/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 4.2141 - accuracy: 0.0278\n",
      "Epoch 00002: val_loss improved from 4.32916 to 3.97493, saving model to model.h5\n",
      "251/251 [==============================] - 20s 80ms/step - loss: 4.2141 - accuracy: 0.0277 - val_loss: 3.9749 - val_accuracy: 0.0360\n",
      "Epoch 3/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 3.8663 - accuracy: 0.0469\n",
      "Epoch 00003: val_loss improved from 3.97493 to 3.69397, saving model to model.h5\n",
      "251/251 [==============================] - 21s 82ms/step - loss: 3.8663 - accuracy: 0.0469 - val_loss: 3.6940 - val_accuracy: 0.0925\n",
      "Epoch 4/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 3.6291 - accuracy: 0.0737\n",
      "Epoch 00004: val_loss improved from 3.69397 to 3.40917, saving model to model.h5\n",
      "251/251 [==============================] - 21s 83ms/step - loss: 3.6292 - accuracy: 0.0740 - val_loss: 3.4092 - val_accuracy: 0.1064\n",
      "Epoch 5/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 3.4454 - accuracy: 0.0886\n",
      "Epoch 00005: val_loss improved from 3.40917 to 3.13017, saving model to model.h5\n",
      "251/251 [==============================] - 21s 82ms/step - loss: 3.4451 - accuracy: 0.0886 - val_loss: 3.1302 - val_accuracy: 0.1549\n",
      "Epoch 6/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 3.2280 - accuracy: 0.1208\n",
      "Epoch 00006: val_loss improved from 3.13017 to 2.95043, saving model to model.h5\n",
      "251/251 [==============================] - 21s 82ms/step - loss: 3.2285 - accuracy: 0.1207 - val_loss: 2.9504 - val_accuracy: 0.1779\n",
      "Epoch 7/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 3.0808 - accuracy: 0.1415\n",
      "Epoch 00007: val_loss improved from 2.95043 to 2.78698, saving model to model.h5\n",
      "251/251 [==============================] - 21s 82ms/step - loss: 3.0808 - accuracy: 0.1414 - val_loss: 2.7870 - val_accuracy: 0.2299\n",
      "Epoch 8/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 2.9256 - accuracy: 0.1678\n",
      "Epoch 00008: val_loss improved from 2.78698 to 2.60705, saving model to model.h5\n",
      "251/251 [==============================] - 21s 83ms/step - loss: 2.9258 - accuracy: 0.1679 - val_loss: 2.6070 - val_accuracy: 0.2514\n",
      "Epoch 9/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 2.8068 - accuracy: 0.1916\n",
      "Epoch 00009: val_loss improved from 2.60705 to 2.50204, saving model to model.h5\n",
      "251/251 [==============================] - 23s 90ms/step - loss: 2.8068 - accuracy: 0.1917 - val_loss: 2.5020 - val_accuracy: 0.2844\n",
      "Epoch 10/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 2.6925 - accuracy: 0.2132\n",
      "Epoch 00010: val_loss improved from 2.50204 to 2.37907, saving model to model.h5\n",
      "251/251 [==============================] - 28s 111ms/step - loss: 2.6924 - accuracy: 0.2132 - val_loss: 2.3791 - val_accuracy: 0.3123\n",
      "Epoch 11/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 2.6014 - accuracy: 0.2364\n",
      "Epoch 00011: val_loss improved from 2.37907 to 2.28826, saving model to model.h5\n",
      "251/251 [==============================] - 25s 100ms/step - loss: 2.6013 - accuracy: 0.2363 - val_loss: 2.2883 - val_accuracy: 0.3293\n",
      "Epoch 12/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 2.5213 - accuracy: 0.2511\n",
      "Epoch 00012: val_loss improved from 2.28826 to 2.24691, saving model to model.h5\n",
      "251/251 [==============================] - 23s 92ms/step - loss: 2.5214 - accuracy: 0.2510 - val_loss: 2.2469 - val_accuracy: 0.3538\n",
      "Epoch 13/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 2.4412 - accuracy: 0.2688\n",
      "Epoch 00013: val_loss improved from 2.24691 to 2.11691, saving model to model.h5\n",
      "251/251 [==============================] - 22s 88ms/step - loss: 2.4412 - accuracy: 0.2688 - val_loss: 2.1169 - val_accuracy: 0.3823\n",
      "Epoch 14/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 2.3775 - accuracy: 0.2859\n",
      "Epoch 00014: val_loss improved from 2.11691 to 2.05651, saving model to model.h5\n",
      "251/251 [==============================] - 22s 87ms/step - loss: 2.3773 - accuracy: 0.2859 - val_loss: 2.0565 - val_accuracy: 0.3858\n",
      "Epoch 15/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 2.2898 - accuracy: 0.3054\n",
      "Epoch 00015: val_loss improved from 2.05651 to 1.99887, saving model to model.h5\n",
      "251/251 [==============================] - 22s 88ms/step - loss: 2.2893 - accuracy: 0.3055 - val_loss: 1.9989 - val_accuracy: 0.4043\n",
      "Epoch 16/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 2.2086 - accuracy: 0.3263\n",
      "Epoch 00016: val_loss improved from 1.99887 to 1.92245, saving model to model.h5\n",
      "251/251 [==============================] - 22s 90ms/step - loss: 2.2086 - accuracy: 0.3263 - val_loss: 1.9225 - val_accuracy: 0.4458\n",
      "Epoch 17/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 2.1518 - accuracy: 0.3280\n",
      "Epoch 00017: val_loss improved from 1.92245 to 1.88021, saving model to model.h5\n",
      "251/251 [==============================] - 22s 89ms/step - loss: 2.1517 - accuracy: 0.3279 - val_loss: 1.8802 - val_accuracy: 0.4578\n",
      "Epoch 18/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 2.1029 - accuracy: 0.3506\n",
      "Epoch 00018: val_loss improved from 1.88021 to 1.78698, saving model to model.h5\n",
      "251/251 [==============================] - 23s 92ms/step - loss: 2.1029 - accuracy: 0.3506 - val_loss: 1.7870 - val_accuracy: 0.4728\n",
      "Epoch 19/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 2.0541 - accuracy: 0.3682\n",
      "Epoch 00019: val_loss improved from 1.78698 to 1.76506, saving model to model.h5\n",
      "251/251 [==============================] - 22s 90ms/step - loss: 2.0541 - accuracy: 0.3682 - val_loss: 1.7651 - val_accuracy: 0.4748\n",
      "Epoch 20/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.9985 - accuracy: 0.3770\n",
      "Epoch 00020: val_loss improved from 1.76506 to 1.70562, saving model to model.h5\n",
      "251/251 [==============================] - 23s 90ms/step - loss: 1.9985 - accuracy: 0.3770 - val_loss: 1.7056 - val_accuracy: 0.4873\n",
      "Epoch 21/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.9364 - accuracy: 0.3920\n",
      "Epoch 00021: val_loss improved from 1.70562 to 1.68893, saving model to model.h5\n",
      "251/251 [==============================] - 23s 91ms/step - loss: 1.9364 - accuracy: 0.3920 - val_loss: 1.6889 - val_accuracy: 0.5087\n",
      "Epoch 22/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.8991 - accuracy: 0.4047\n",
      "Epoch 00022: val_loss improved from 1.68893 to 1.62864, saving model to model.h5\n",
      "251/251 [==============================] - 23s 91ms/step - loss: 1.8991 - accuracy: 0.4047 - val_loss: 1.6286 - val_accuracy: 0.5152\n",
      "Epoch 23/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.8572 - accuracy: 0.4200\n",
      "Epoch 00023: val_loss did not improve from 1.62864\n",
      "251/251 [==============================] - 21s 85ms/step - loss: 1.8570 - accuracy: 0.4201 - val_loss: 1.6501 - val_accuracy: 0.5097\n",
      "Epoch 24/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.8172 - accuracy: 0.4344\n",
      "Epoch 00024: val_loss improved from 1.62864 to 1.60911, saving model to model.h5\n",
      "251/251 [==============================] - 21s 85ms/step - loss: 1.8175 - accuracy: 0.4342 - val_loss: 1.6091 - val_accuracy: 0.5207\n",
      "Epoch 25/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.7977 - accuracy: 0.4329\n",
      "Epoch 00025: val_loss improved from 1.60911 to 1.60057, saving model to model.h5\n",
      "251/251 [==============================] - 21s 85ms/step - loss: 1.7977 - accuracy: 0.4328 - val_loss: 1.6006 - val_accuracy: 0.5267\n",
      "Epoch 26/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.7604 - accuracy: 0.4426\n",
      "Epoch 00026: val_loss improved from 1.60057 to 1.53701, saving model to model.h5\n",
      "251/251 [==============================] - 21s 85ms/step - loss: 1.7608 - accuracy: 0.4426 - val_loss: 1.5370 - val_accuracy: 0.5422\n",
      "Epoch 27/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.6923 - accuracy: 0.4602\n",
      "Epoch 00027: val_loss did not improve from 1.53701\n",
      "251/251 [==============================] - 21s 85ms/step - loss: 1.6925 - accuracy: 0.4602 - val_loss: 1.5382 - val_accuracy: 0.5362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.6912 - accuracy: 0.4611\n",
      "Epoch 00028: val_loss improved from 1.53701 to 1.50611, saving model to model.h5\n",
      "251/251 [==============================] - 21s 82ms/step - loss: 1.6908 - accuracy: 0.4612 - val_loss: 1.5061 - val_accuracy: 0.5587\n",
      "Epoch 29/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.6325 - accuracy: 0.4681\n",
      "Epoch 00029: val_loss improved from 1.50611 to 1.49190, saving model to model.h5\n",
      "251/251 [==============================] - 22s 87ms/step - loss: 1.6325 - accuracy: 0.4681 - val_loss: 1.4919 - val_accuracy: 0.5662\n",
      "Epoch 30/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.6268 - accuracy: 0.4768\n",
      "Epoch 00030: val_loss improved from 1.49190 to 1.47826, saving model to model.h5\n",
      "251/251 [==============================] - 25s 98ms/step - loss: 1.6268 - accuracy: 0.4768 - val_loss: 1.4783 - val_accuracy: 0.5707\n",
      "Epoch 31/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.5913 - accuracy: 0.4861\n",
      "Epoch 00031: val_loss improved from 1.47826 to 1.45580, saving model to model.h5\n",
      "251/251 [==============================] - 22s 88ms/step - loss: 1.5916 - accuracy: 0.4861 - val_loss: 1.4558 - val_accuracy: 0.5752\n",
      "Epoch 32/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.5683 - accuracy: 0.4960\n",
      "Epoch 00032: val_loss improved from 1.45580 to 1.43756, saving model to model.h5\n",
      "251/251 [==============================] - 24s 94ms/step - loss: 1.5687 - accuracy: 0.4958 - val_loss: 1.4376 - val_accuracy: 0.5817\n",
      "Epoch 33/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.5258 - accuracy: 0.5102\n",
      "Epoch 00033: val_loss did not improve from 1.43756\n",
      "251/251 [==============================] - 21s 84ms/step - loss: 1.5258 - accuracy: 0.5102 - val_loss: 1.4432 - val_accuracy: 0.5837\n",
      "Epoch 34/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.4766 - accuracy: 0.5246\n",
      "Epoch 00034: val_loss did not improve from 1.43756\n",
      "251/251 [==============================] - 20s 80ms/step - loss: 1.4767 - accuracy: 0.5246 - val_loss: 1.4625 - val_accuracy: 0.5837\n",
      "Epoch 35/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.4459 - accuracy: 0.5350\n",
      "Epoch 00035: val_loss improved from 1.43756 to 1.43671, saving model to model.h5\n",
      "251/251 [==============================] - 19s 74ms/step - loss: 1.4461 - accuracy: 0.5349 - val_loss: 1.4367 - val_accuracy: 0.5862\n",
      "Epoch 36/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.4073 - accuracy: 0.5430\n",
      "Epoch 00036: val_loss improved from 1.43671 to 1.42978, saving model to model.h5\n",
      "251/251 [==============================] - 22s 88ms/step - loss: 1.4073 - accuracy: 0.5430 - val_loss: 1.4298 - val_accuracy: 0.5907\n",
      "Epoch 37/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.3977 - accuracy: 0.5452\n",
      "Epoch 00037: val_loss improved from 1.42978 to 1.41595, saving model to model.h5\n",
      "251/251 [==============================] - 26s 105ms/step - loss: 1.3976 - accuracy: 0.5453 - val_loss: 1.4159 - val_accuracy: 0.6037\n",
      "Epoch 38/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.3391 - accuracy: 0.5569\n",
      "Epoch 00038: val_loss improved from 1.41595 to 1.38341, saving model to model.h5\n",
      "251/251 [==============================] - 25s 101ms/step - loss: 1.3391 - accuracy: 0.5569 - val_loss: 1.3834 - val_accuracy: 0.6032\n",
      "Epoch 39/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.3228 - accuracy: 0.5642\n",
      "Epoch 00039: val_loss improved from 1.38341 to 1.36265, saving model to model.h5\n",
      "251/251 [==============================] - 27s 106ms/step - loss: 1.3224 - accuracy: 0.5644 - val_loss: 1.3626 - val_accuracy: 0.6192\n",
      "Epoch 40/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.3018 - accuracy: 0.5720\n",
      "Epoch 00040: val_loss improved from 1.36265 to 1.36014, saving model to model.h5\n",
      "251/251 [==============================] - 27s 106ms/step - loss: 1.3018 - accuracy: 0.5720 - val_loss: 1.3601 - val_accuracy: 0.6277\n",
      "Epoch 41/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.2914 - accuracy: 0.5819\n",
      "Epoch 00041: val_loss improved from 1.36014 to 1.35651, saving model to model.h5\n",
      "251/251 [==============================] - 25s 99ms/step - loss: 1.2911 - accuracy: 0.5819 - val_loss: 1.3565 - val_accuracy: 0.6217\n",
      "Epoch 42/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.2503 - accuracy: 0.5850\n",
      "Epoch 00042: val_loss did not improve from 1.35651\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 1.2503 - accuracy: 0.5850 - val_loss: 1.3832 - val_accuracy: 0.6327\n",
      "Epoch 43/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.2336 - accuracy: 0.5953\n",
      "Epoch 00043: val_loss improved from 1.35651 to 1.35074, saving model to model.h5\n",
      "251/251 [==============================] - 26s 102ms/step - loss: 1.2334 - accuracy: 0.5953 - val_loss: 1.3507 - val_accuracy: 0.6372\n",
      "Epoch 44/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.1979 - accuracy: 0.5960\n",
      "Epoch 00044: val_loss did not improve from 1.35074\n",
      "251/251 [==============================] - 19s 76ms/step - loss: 1.1978 - accuracy: 0.5960 - val_loss: 1.4410 - val_accuracy: 0.6217\n",
      "Epoch 45/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.2629 - accuracy: 0.5861\n",
      "Epoch 00045: val_loss improved from 1.35074 to 1.34681, saving model to model.h5\n",
      "251/251 [==============================] - 18s 73ms/step - loss: 1.2628 - accuracy: 0.5862 - val_loss: 1.3468 - val_accuracy: 0.6292\n",
      "Epoch 46/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.1725 - accuracy: 0.6116\n",
      "Epoch 00046: val_loss did not improve from 1.34681\n",
      "251/251 [==============================] - 18s 73ms/step - loss: 1.1721 - accuracy: 0.6118 - val_loss: 1.3866 - val_accuracy: 0.6297\n",
      "Epoch 47/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.1513 - accuracy: 0.6162\n",
      "Epoch 00047: val_loss improved from 1.34681 to 1.34363, saving model to model.h5\n",
      "251/251 [==============================] - 22s 87ms/step - loss: 1.1514 - accuracy: 0.6163 - val_loss: 1.3436 - val_accuracy: 0.6497\n",
      "Epoch 48/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.0900 - accuracy: 0.6400\n",
      "Epoch 00048: val_loss did not improve from 1.34363\n",
      "251/251 [==============================] - 25s 99ms/step - loss: 1.0913 - accuracy: 0.6399 - val_loss: 1.4173 - val_accuracy: 0.6337\n",
      "Epoch 49/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.1320 - accuracy: 0.6271\n",
      "Epoch 00049: val_loss improved from 1.34363 to 1.33687, saving model to model.h5\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 1.1320 - accuracy: 0.6270 - val_loss: 1.3369 - val_accuracy: 0.6442\n",
      "Epoch 50/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.0646 - accuracy: 0.6410\n",
      "Epoch 00050: val_loss did not improve from 1.33687\n",
      "251/251 [==============================] - 25s 102ms/step - loss: 1.0645 - accuracy: 0.6411 - val_loss: 1.4024 - val_accuracy: 0.6562\n",
      "Epoch 51/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.0427 - accuracy: 0.6486\n",
      "Epoch 00051: val_loss did not improve from 1.33687\n",
      "251/251 [==============================] - 20s 81ms/step - loss: 1.0425 - accuracy: 0.6486 - val_loss: 1.3860 - val_accuracy: 0.6582\n",
      "Epoch 52/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.0454 - accuracy: 0.6469\n",
      "Epoch 00052: val_loss did not improve from 1.33687\n",
      "251/251 [==============================] - 19s 76ms/step - loss: 1.0455 - accuracy: 0.6468 - val_loss: 1.3690 - val_accuracy: 0.6462\n",
      "Epoch 53/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.0017 - accuracy: 0.6579\n",
      "Epoch 00053: val_loss did not improve from 1.33687\n",
      "251/251 [==============================] - 20s 78ms/step - loss: 1.0017 - accuracy: 0.6579 - val_loss: 1.3882 - val_accuracy: 0.6627\n",
      "Epoch 54/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.9773 - accuracy: 0.6711\n",
      "Epoch 00054: val_loss improved from 1.33687 to 1.32746, saving model to model.h5\n",
      "251/251 [==============================] - 19s 74ms/step - loss: 0.9777 - accuracy: 0.6709 - val_loss: 1.3275 - val_accuracy: 0.6762\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/251 [============================>.] - ETA: 0s - loss: 1.0022 - accuracy: 0.6619\n",
      "Epoch 00055: val_loss did not improve from 1.32746\n",
      "251/251 [==============================] - 19s 77ms/step - loss: 1.0026 - accuracy: 0.6618 - val_loss: 1.4188 - val_accuracy: 0.6622\n",
      "Epoch 56/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.9672 - accuracy: 0.6740\n",
      "Epoch 00056: val_loss did not improve from 1.32746\n",
      "251/251 [==============================] - 22s 87ms/step - loss: 0.9670 - accuracy: 0.6741 - val_loss: 1.4549 - val_accuracy: 0.6647\n",
      "Epoch 57/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.9549 - accuracy: 0.6837\n",
      "Epoch 00057: val_loss did not improve from 1.32746\n",
      "251/251 [==============================] - 19s 75ms/step - loss: 0.9546 - accuracy: 0.6839 - val_loss: 1.4007 - val_accuracy: 0.6667\n",
      "Epoch 58/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.9149 - accuracy: 0.6886\n",
      "Epoch 00058: val_loss did not improve from 1.32746\n",
      "251/251 [==============================] - 19s 76ms/step - loss: 0.9150 - accuracy: 0.6887 - val_loss: 1.4111 - val_accuracy: 0.6642\n",
      "Epoch 59/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.9581 - accuracy: 0.6764\n",
      "Epoch 00059: val_loss did not improve from 1.32746\n",
      "251/251 [==============================] - 20s 79ms/step - loss: 0.9581 - accuracy: 0.6764 - val_loss: 1.4775 - val_accuracy: 0.6617\n",
      "Epoch 60/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.9024 - accuracy: 0.6906\n",
      "Epoch 00060: val_loss did not improve from 1.32746\n",
      "251/251 [==============================] - 20s 78ms/step - loss: 0.9030 - accuracy: 0.6905 - val_loss: 1.4273 - val_accuracy: 0.6597\n",
      "Epoch 61/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.8618 - accuracy: 0.7085\n",
      "Epoch 00061: val_loss did not improve from 1.32746\n",
      "251/251 [==============================] - 20s 79ms/step - loss: 0.8621 - accuracy: 0.7084 - val_loss: 1.4666 - val_accuracy: 0.6607\n",
      "Epoch 62/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.8658 - accuracy: 0.7032\n",
      "Epoch 00062: val_loss did not improve from 1.32746\n",
      "251/251 [==============================] - 19s 77ms/step - loss: 0.8656 - accuracy: 0.7032 - val_loss: 1.6600 - val_accuracy: 0.6612\n",
      "Epoch 63/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.8625 - accuracy: 0.7040\n",
      "Epoch 00063: val_loss did not improve from 1.32746\n",
      "251/251 [==============================] - 25s 99ms/step - loss: 0.8625 - accuracy: 0.7040 - val_loss: 1.5090 - val_accuracy: 0.6782\n",
      "Epoch 64/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.8235 - accuracy: 0.7124\n",
      "Epoch 00064: val_loss did not improve from 1.32746\n",
      "251/251 [==============================] - 21s 85ms/step - loss: 0.8236 - accuracy: 0.7124 - val_loss: 1.4528 - val_accuracy: 0.6822\n",
      "Epoch 65/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.8525 - accuracy: 0.7072\n",
      "Epoch 00065: val_loss did not improve from 1.32746\n",
      "251/251 [==============================] - 20s 78ms/step - loss: 0.8529 - accuracy: 0.7071 - val_loss: 1.4178 - val_accuracy: 0.6847\n",
      "Epoch 66/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.8196 - accuracy: 0.7134\n",
      "Epoch 00066: val_loss did not improve from 1.32746\n",
      "251/251 [==============================] - 22s 86ms/step - loss: 0.8200 - accuracy: 0.7134 - val_loss: 1.5517 - val_accuracy: 0.6637\n",
      "Epoch 67/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.8137 - accuracy: 0.7209\n",
      "Epoch 00067: val_loss did not improve from 1.32746\n",
      "251/251 [==============================] - 23s 92ms/step - loss: 0.8137 - accuracy: 0.7209 - val_loss: 1.5501 - val_accuracy: 0.6722\n",
      "Epoch 68/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.8089 - accuracy: 0.7287\n",
      "Epoch 00068: val_loss did not improve from 1.32746\n",
      "251/251 [==============================] - 26s 105ms/step - loss: 0.8089 - accuracy: 0.7287 - val_loss: 1.4992 - val_accuracy: 0.6902\n",
      "Epoch 69/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.8299 - accuracy: 0.7132\n",
      "Epoch 00069: val_loss did not improve from 1.32746\n",
      "251/251 [==============================] - 22s 86ms/step - loss: 0.8297 - accuracy: 0.7134 - val_loss: 1.5369 - val_accuracy: 0.6722\n",
      "Epoch 70/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.7657 - accuracy: 0.7352\n",
      "Epoch 00070: val_loss did not improve from 1.32746\n",
      "251/251 [==============================] - 25s 98ms/step - loss: 0.7663 - accuracy: 0.7350 - val_loss: 1.6164 - val_accuracy: 0.6697\n",
      "Epoch 71/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.7516 - accuracy: 0.7385\n",
      "Epoch 00071: val_loss did not improve from 1.32746\n",
      "251/251 [==============================] - 27s 106ms/step - loss: 0.7516 - accuracy: 0.7385 - val_loss: 1.5888 - val_accuracy: 0.6822\n",
      "Epoch 72/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.7486 - accuracy: 0.7365\n",
      "Epoch 00072: val_loss did not improve from 1.32746\n",
      "251/251 [==============================] - 28s 110ms/step - loss: 0.7484 - accuracy: 0.7366 - val_loss: 1.6463 - val_accuracy: 0.6802\n",
      "Epoch 73/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.7099 - accuracy: 0.7459\n",
      "Epoch 00073: val_loss did not improve from 1.32746\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.7098 - accuracy: 0.7460 - val_loss: 1.7012 - val_accuracy: 0.6797\n",
      "Epoch 74/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.7023 - accuracy: 0.7506\n",
      "Epoch 00074: val_loss did not improve from 1.32746\n",
      "251/251 [==============================] - 26s 106ms/step - loss: 0.7023 - accuracy: 0.7506 - val_loss: 1.5766 - val_accuracy: 0.6952\n",
      "Epoch 75/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.7154 - accuracy: 0.7524\n",
      "Epoch 00075: val_loss did not improve from 1.32746\n",
      "251/251 [==============================] - 27s 108ms/step - loss: 0.7154 - accuracy: 0.7523 - val_loss: 1.6799 - val_accuracy: 0.6757\n",
      "Epoch 76/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.7062 - accuracy: 0.7485\n",
      "Epoch 00076: val_loss did not improve from 1.32746\n",
      "251/251 [==============================] - 26s 105ms/step - loss: 0.7071 - accuracy: 0.7485 - val_loss: 1.6368 - val_accuracy: 0.6872\n",
      "Epoch 77/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.7022 - accuracy: 0.7567\n",
      "Epoch 00077: val_loss did not improve from 1.32746\n",
      "251/251 [==============================] - 26s 105ms/step - loss: 0.7020 - accuracy: 0.7568 - val_loss: 1.6156 - val_accuracy: 0.6907\n",
      "Epoch 78/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.7189 - accuracy: 0.7516\n",
      "Epoch 00078: val_loss did not improve from 1.32746\n",
      "251/251 [==============================] - 21s 82ms/step - loss: 0.7190 - accuracy: 0.7516 - val_loss: 1.6409 - val_accuracy: 0.6902\n",
      "Epoch 79/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.6533 - accuracy: 0.7671\n",
      "Epoch 00079: val_loss did not improve from 1.32746\n",
      "251/251 [==============================] - 23s 94ms/step - loss: 0.6533 - accuracy: 0.7671 - val_loss: 1.7540 - val_accuracy: 0.6922\n",
      "Epoch 80/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.6888 - accuracy: 0.7565\n",
      "Epoch 00080: val_loss did not improve from 1.32746\n",
      "251/251 [==============================] - 29s 117ms/step - loss: 0.6888 - accuracy: 0.7565 - val_loss: 1.7741 - val_accuracy: 0.6817\n",
      "Epoch 81/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.6462 - accuracy: 0.7692\n",
      "Epoch 00081: val_loss did not improve from 1.32746\n",
      "251/251 [==============================] - 25s 100ms/step - loss: 0.6460 - accuracy: 0.7693 - val_loss: 1.7142 - val_accuracy: 0.6897\n",
      "Epoch 82/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.6398 - accuracy: 0.7757\n",
      "Epoch 00082: val_loss did not improve from 1.32746\n",
      "251/251 [==============================] - 25s 98ms/step - loss: 0.6397 - accuracy: 0.7758 - val_loss: 1.7746 - val_accuracy: 0.6842\n",
      "Epoch 83/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.6153 - accuracy: 0.7815\n",
      "Epoch 00083: val_loss did not improve from 1.32746\n",
      "251/251 [==============================] - 25s 101ms/step - loss: 0.6153 - accuracy: 0.7815 - val_loss: 1.7445 - val_accuracy: 0.6917\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - ETA: 0s - loss: 0.6376 - accuracy: 0.7806\n",
      "Epoch 00084: val_loss did not improve from 1.32746\n",
      "251/251 [==============================] - 28s 113ms/step - loss: 0.6376 - accuracy: 0.7806 - val_loss: 1.7580 - val_accuracy: 0.6887\n",
      "Epoch 85/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.6081 - accuracy: 0.7836\n",
      "Epoch 00085: val_loss did not improve from 1.32746\n",
      "251/251 [==============================] - 20s 79ms/step - loss: 0.6084 - accuracy: 0.7835 - val_loss: 1.7240 - val_accuracy: 0.7096\n",
      "Epoch 86/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.6152 - accuracy: 0.7806\n",
      "Epoch 00086: val_loss did not improve from 1.32746\n",
      "251/251 [==============================] - 18s 72ms/step - loss: 0.6150 - accuracy: 0.7807 - val_loss: 1.9603 - val_accuracy: 0.6827\n",
      "Epoch 87/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.6544 - accuracy: 0.7774\n",
      "Epoch 00087: val_loss did not improve from 1.32746\n",
      "251/251 [==============================] - 18s 72ms/step - loss: 0.6548 - accuracy: 0.7772 - val_loss: 1.7448 - val_accuracy: 0.6887\n",
      "Epoch 88/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.6127 - accuracy: 0.7820\n",
      "Epoch 00088: val_loss did not improve from 1.32746\n",
      "251/251 [==============================] - 18s 72ms/step - loss: 0.6125 - accuracy: 0.7821 - val_loss: 1.8716 - val_accuracy: 0.6877\n",
      "Epoch 89/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.6193 - accuracy: 0.7830\n",
      "Epoch 00089: val_loss did not improve from 1.32746\n",
      "251/251 [==============================] - 18s 72ms/step - loss: 0.6194 - accuracy: 0.7830 - val_loss: 1.9035 - val_accuracy: 0.6992\n",
      "Epoch 90/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.5926 - accuracy: 0.7928\n",
      "Epoch 00090: val_loss did not improve from 1.32746\n",
      "251/251 [==============================] - 18s 73ms/step - loss: 0.5924 - accuracy: 0.7928 - val_loss: 1.8075 - val_accuracy: 0.6917\n",
      "Epoch 91/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.5663 - accuracy: 0.7993\n",
      "Epoch 00091: val_loss did not improve from 1.32746\n",
      "251/251 [==============================] - 18s 72ms/step - loss: 0.5665 - accuracy: 0.7992 - val_loss: 1.9050 - val_accuracy: 0.6982\n",
      "Epoch 92/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.5705 - accuracy: 0.8087\n",
      "Epoch 00092: val_loss did not improve from 1.32746\n",
      "251/251 [==============================] - 27s 108ms/step - loss: 0.5705 - accuracy: 0.8087 - val_loss: 1.9498 - val_accuracy: 0.6957\n",
      "Epoch 93/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.5548 - accuracy: 0.8031\n",
      "Epoch 00093: val_loss did not improve from 1.32746\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.5549 - accuracy: 0.8031 - val_loss: 1.8895 - val_accuracy: 0.6987\n",
      "Epoch 94/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.6028 - accuracy: 0.7861\n",
      "Epoch 00094: val_loss did not improve from 1.32746\n",
      "251/251 [==============================] - 18s 73ms/step - loss: 0.6027 - accuracy: 0.7861 - val_loss: 1.9240 - val_accuracy: 0.6822\n",
      "Epoch 95/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.5820 - accuracy: 0.7975\n",
      "Epoch 00095: val_loss did not improve from 1.32746\n",
      "251/251 [==============================] - 18s 73ms/step - loss: 0.5821 - accuracy: 0.7973 - val_loss: 1.9059 - val_accuracy: 0.6907\n",
      "Epoch 96/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.5321 - accuracy: 0.8110\n",
      "Epoch 00096: val_loss did not improve from 1.32746\n",
      "251/251 [==============================] - 18s 73ms/step - loss: 0.5320 - accuracy: 0.8111 - val_loss: 1.9763 - val_accuracy: 0.6947\n",
      "Epoch 97/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.5366 - accuracy: 0.8096\n",
      "Epoch 00097: val_loss did not improve from 1.32746\n",
      "251/251 [==============================] - 18s 73ms/step - loss: 0.5364 - accuracy: 0.8097 - val_loss: 1.9246 - val_accuracy: 0.6952\n",
      "Epoch 98/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.5715 - accuracy: 0.8070\n",
      "Epoch 00098: val_loss did not improve from 1.32746\n",
      "251/251 [==============================] - 18s 73ms/step - loss: 0.5714 - accuracy: 0.8069 - val_loss: 1.9964 - val_accuracy: 0.6862\n",
      "Epoch 99/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.5184 - accuracy: 0.8174\n",
      "Epoch 00099: val_loss did not improve from 1.32746\n",
      "251/251 [==============================] - 18s 73ms/step - loss: 0.5183 - accuracy: 0.8174 - val_loss: 2.1322 - val_accuracy: 0.7031\n",
      "Epoch 100/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.5081 - accuracy: 0.8186\n",
      "Epoch 00100: val_loss did not improve from 1.32746\n",
      "251/251 [==============================] - 19s 75ms/step - loss: 0.5082 - accuracy: 0.8186 - val_loss: 1.9790 - val_accuracy: 0.6952\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(train_X, train_Y,\n",
    "                 epochs = 100,\n",
    "                 batch_size = 32,\n",
    "                 validation_data = (val_X, val_Y),\n",
    "                 callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Bidirectional LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 84, 128)           299904    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 256)               263168    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 78)                2574      \n",
      "=================================================================\n",
      "Total params: 573,870\n",
      "Trainable params: 273,966\n",
      "Non-trainable params: 299,904\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model(vocab_size, max_length):\n",
    "  model = Sequential()\n",
    "  model.add(Embedding(vocab_size, 128, input_length = max_length, trainable = False))\n",
    "  model.add(Bidirectional(LSTM(128)))\n",
    "  model.add(Dense(32, activation = \"relu\"))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Dense(78, activation = \"softmax\"))\n",
    "  \n",
    "  return model\n",
    "\n",
    "model_lstm = create_model(vocab_size, max_length)\n",
    "\n",
    "model_lstm.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 4.3283 - accuracy: 0.0184\n",
      "Epoch 00001: val_loss improved from inf to 4.23865, saving model to model.h5\n",
      "251/251 [==============================] - 23s 92ms/step - loss: 4.3278 - accuracy: 0.0184 - val_loss: 4.2386 - val_accuracy: 0.0150\n",
      "Epoch 2/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 4.1311 - accuracy: 0.0318\n",
      "Epoch 00002: val_loss improved from 4.23865 to 3.97603, saving model to model.h5\n",
      "251/251 [==============================] - 23s 90ms/step - loss: 4.1311 - accuracy: 0.0317 - val_loss: 3.9760 - val_accuracy: 0.0500\n",
      "Epoch 3/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 3.8447 - accuracy: 0.0582\n",
      "Epoch 00003: val_loss improved from 3.97603 to 3.59888, saving model to model.h5\n",
      "251/251 [==============================] - 23s 90ms/step - loss: 3.8447 - accuracy: 0.0582 - val_loss: 3.5989 - val_accuracy: 0.0815\n",
      "Epoch 4/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 3.5645 - accuracy: 0.0911\n",
      "Epoch 00004: val_loss improved from 3.59888 to 3.33815, saving model to model.h5\n",
      "251/251 [==============================] - 23s 90ms/step - loss: 3.5644 - accuracy: 0.0911 - val_loss: 3.3381 - val_accuracy: 0.1119\n",
      "Epoch 5/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 3.3655 - accuracy: 0.1091\n",
      "Epoch 00005: val_loss improved from 3.33815 to 3.15023, saving model to model.h5\n",
      "251/251 [==============================] - 23s 90ms/step - loss: 3.3658 - accuracy: 0.1091 - val_loss: 3.1502 - val_accuracy: 0.1509\n",
      "Epoch 6/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 3.1973 - accuracy: 0.1281\n",
      "Epoch 00006: val_loss improved from 3.15023 to 2.97285, saving model to model.h5\n",
      "251/251 [==============================] - 23s 90ms/step - loss: 3.1969 - accuracy: 0.1281 - val_loss: 2.9729 - val_accuracy: 0.1669\n",
      "Epoch 7/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 3.0852 - accuracy: 0.1417\n",
      "Epoch 00007: val_loss improved from 2.97285 to 2.87104, saving model to model.h5\n",
      "251/251 [==============================] - 23s 90ms/step - loss: 3.0852 - accuracy: 0.1417 - val_loss: 2.8710 - val_accuracy: 0.1954\n",
      "Epoch 8/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 2.9413 - accuracy: 0.1628\n",
      "Epoch 00008: val_loss improved from 2.87104 to 2.74773, saving model to model.h5\n",
      "251/251 [==============================] - 23s 90ms/step - loss: 2.9414 - accuracy: 0.1627 - val_loss: 2.7477 - val_accuracy: 0.2079\n",
      "Epoch 9/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 2.8181 - accuracy: 0.1902\n",
      "Epoch 00009: val_loss improved from 2.74773 to 2.61223, saving model to model.h5\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 2.8184 - accuracy: 0.1902 - val_loss: 2.6122 - val_accuracy: 0.2414\n",
      "Epoch 10/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 2.7171 - accuracy: 0.2114\n",
      "Epoch 00010: val_loss improved from 2.61223 to 2.45857, saving model to model.h5\n",
      "251/251 [==============================] - 23s 90ms/step - loss: 2.7174 - accuracy: 0.2114 - val_loss: 2.4586 - val_accuracy: 0.2869\n",
      "Epoch 11/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 2.6902 - accuracy: 0.2139\n",
      "Epoch 00011: val_loss improved from 2.45857 to 2.42147, saving model to model.h5\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 2.6899 - accuracy: 0.2140 - val_loss: 2.4215 - val_accuracy: 0.2854\n",
      "Epoch 12/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 2.5676 - accuracy: 0.2368\n",
      "Epoch 00012: val_loss improved from 2.42147 to 2.35615, saving model to model.h5\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 2.5677 - accuracy: 0.2367 - val_loss: 2.3562 - val_accuracy: 0.3063\n",
      "Epoch 13/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 2.4719 - accuracy: 0.2625\n",
      "Epoch 00013: val_loss improved from 2.35615 to 2.28385, saving model to model.h5\n",
      "251/251 [==============================] - 32s 129ms/step - loss: 2.4718 - accuracy: 0.2625 - val_loss: 2.2839 - val_accuracy: 0.3283\n",
      "Epoch 14/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 2.4045 - accuracy: 0.2765\n",
      "Epoch 00014: val_loss improved from 2.28385 to 2.20581, saving model to model.h5\n",
      "251/251 [==============================] - 31s 122ms/step - loss: 2.4043 - accuracy: 0.2765 - val_loss: 2.2058 - val_accuracy: 0.3313\n",
      "Epoch 15/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 2.3567 - accuracy: 0.2840\n",
      "Epoch 00015: val_loss did not improve from 2.20581\n",
      "251/251 [==============================] - 45s 178ms/step - loss: 2.3567 - accuracy: 0.2840 - val_loss: 2.2380 - val_accuracy: 0.3513\n",
      "Epoch 16/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 2.3286 - accuracy: 0.2924\n",
      "Epoch 00016: val_loss improved from 2.20581 to 2.09581, saving model to model.h5\n",
      "251/251 [==============================] - 27s 108ms/step - loss: 2.3287 - accuracy: 0.2925 - val_loss: 2.0958 - val_accuracy: 0.3898\n",
      "Epoch 17/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 2.2494 - accuracy: 0.3121\n",
      "Epoch 00017: val_loss improved from 2.09581 to 2.05365, saving model to model.h5\n",
      "251/251 [==============================] - 22s 89ms/step - loss: 2.2496 - accuracy: 0.3120 - val_loss: 2.0536 - val_accuracy: 0.3913\n",
      "Epoch 18/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 2.1781 - accuracy: 0.3237\n",
      "Epoch 00018: val_loss improved from 2.05365 to 1.98880, saving model to model.h5\n",
      "251/251 [==============================] - 22s 89ms/step - loss: 2.1781 - accuracy: 0.3238 - val_loss: 1.9888 - val_accuracy: 0.4168\n",
      "Epoch 19/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 2.1501 - accuracy: 0.3338\n",
      "Epoch 00019: val_loss improved from 1.98880 to 1.94579, saving model to model.h5\n",
      "251/251 [==============================] - 24s 94ms/step - loss: 2.1497 - accuracy: 0.3339 - val_loss: 1.9458 - val_accuracy: 0.4293\n",
      "Epoch 20/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 2.0849 - accuracy: 0.3528\n",
      "Epoch 00020: val_loss improved from 1.94579 to 1.88991, saving model to model.h5\n",
      "251/251 [==============================] - 22s 89ms/step - loss: 2.0847 - accuracy: 0.3529 - val_loss: 1.8899 - val_accuracy: 0.4363\n",
      "Epoch 21/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 2.0381 - accuracy: 0.3719\n",
      "Epoch 00021: val_loss improved from 1.88991 to 1.84056, saving model to model.h5\n",
      "251/251 [==============================] - 22s 89ms/step - loss: 2.0384 - accuracy: 0.3717 - val_loss: 1.8406 - val_accuracy: 0.4543\n",
      "Epoch 22/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.9939 - accuracy: 0.3829\n",
      "Epoch 00022: val_loss did not improve from 1.84056\n",
      "251/251 [==============================] - 22s 89ms/step - loss: 1.9935 - accuracy: 0.3830 - val_loss: 1.8624 - val_accuracy: 0.4548\n",
      "Epoch 23/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.9408 - accuracy: 0.3981\n",
      "Epoch 00023: val_loss did not improve from 1.84056\n",
      "251/251 [==============================] - 24s 95ms/step - loss: 1.9412 - accuracy: 0.3982 - val_loss: 1.8515 - val_accuracy: 0.4613\n",
      "Epoch 24/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.8984 - accuracy: 0.4086\n",
      "Epoch 00024: val_loss improved from 1.84056 to 1.75547, saving model to model.h5\n",
      "251/251 [==============================] - 27s 109ms/step - loss: 1.8981 - accuracy: 0.4087 - val_loss: 1.7555 - val_accuracy: 0.4868\n",
      "Epoch 25/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.8770 - accuracy: 0.4198\n",
      "Epoch 00025: val_loss improved from 1.75547 to 1.73056, saving model to model.h5\n",
      "251/251 [==============================] - 22s 89ms/step - loss: 1.8784 - accuracy: 0.4197 - val_loss: 1.7306 - val_accuracy: 0.4953\n",
      "Epoch 26/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.8316 - accuracy: 0.4226\n",
      "Epoch 00026: val_loss improved from 1.73056 to 1.71445, saving model to model.h5\n",
      "251/251 [==============================] - 25s 101ms/step - loss: 1.8316 - accuracy: 0.4226 - val_loss: 1.7144 - val_accuracy: 0.5002\n",
      "Epoch 27/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.8079 - accuracy: 0.4286\n",
      "Epoch 00027: val_loss improved from 1.71445 to 1.67843, saving model to model.h5\n",
      "251/251 [==============================] - 35s 141ms/step - loss: 1.8083 - accuracy: 0.4286 - val_loss: 1.6784 - val_accuracy: 0.5127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.7536 - accuracy: 0.4535\n",
      "Epoch 00028: val_loss did not improve from 1.67843\n",
      "251/251 [==============================] - 28s 110ms/step - loss: 1.7535 - accuracy: 0.4536 - val_loss: 1.7034 - val_accuracy: 0.4988\n",
      "Epoch 29/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.7234 - accuracy: 0.4550\n",
      "Epoch 00029: val_loss did not improve from 1.67843\n",
      "251/251 [==============================] - 22s 89ms/step - loss: 1.7238 - accuracy: 0.4550 - val_loss: 1.7211 - val_accuracy: 0.5042\n",
      "Epoch 30/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.8046 - accuracy: 0.4397\n",
      "Epoch 00030: val_loss improved from 1.67843 to 1.65198, saving model to model.h5\n",
      "251/251 [==============================] - 22s 89ms/step - loss: 1.8046 - accuracy: 0.4397 - val_loss: 1.6520 - val_accuracy: 0.5092\n",
      "Epoch 31/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.6849 - accuracy: 0.4712\n",
      "Epoch 00031: val_loss improved from 1.65198 to 1.64578, saving model to model.h5\n",
      "251/251 [==============================] - 29s 114ms/step - loss: 1.6849 - accuracy: 0.4712 - val_loss: 1.6458 - val_accuracy: 0.5392\n",
      "Epoch 32/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.6350 - accuracy: 0.4849\n",
      "Epoch 00032: val_loss improved from 1.64578 to 1.59040, saving model to model.h5\n",
      "251/251 [==============================] - 41s 163ms/step - loss: 1.6350 - accuracy: 0.4849 - val_loss: 1.5904 - val_accuracy: 0.5382\n",
      "Epoch 33/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.6103 - accuracy: 0.4923\n",
      "Epoch 00033: val_loss improved from 1.59040 to 1.56940, saving model to model.h5\n",
      "251/251 [==============================] - 42s 166ms/step - loss: 1.6103 - accuracy: 0.4923 - val_loss: 1.5694 - val_accuracy: 0.5457\n",
      "Epoch 34/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.5683 - accuracy: 0.5051\n",
      "Epoch 00034: val_loss did not improve from 1.56940\n",
      "251/251 [==============================] - 41s 165ms/step - loss: 1.5683 - accuracy: 0.5051 - val_loss: 1.6619 - val_accuracy: 0.5217\n",
      "Epoch 35/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.5470 - accuracy: 0.5086\n",
      "Epoch 00035: val_loss did not improve from 1.56940\n",
      "251/251 [==============================] - 42s 166ms/step - loss: 1.5470 - accuracy: 0.5086 - val_loss: 1.5719 - val_accuracy: 0.5507\n",
      "Epoch 36/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.5344 - accuracy: 0.5242\n",
      "Epoch 00036: val_loss did not improve from 1.56940\n",
      "251/251 [==============================] - 42s 166ms/step - loss: 1.5345 - accuracy: 0.5241 - val_loss: 1.6119 - val_accuracy: 0.5492\n",
      "Epoch 37/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.5130 - accuracy: 0.5177\n",
      "Epoch 00037: val_loss improved from 1.56940 to 1.54923, saving model to model.h5\n",
      "251/251 [==============================] - 42s 168ms/step - loss: 1.5130 - accuracy: 0.5177 - val_loss: 1.5492 - val_accuracy: 0.5582\n",
      "Epoch 38/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.4740 - accuracy: 0.5348\n",
      "Epoch 00038: val_loss improved from 1.54923 to 1.54885, saving model to model.h5\n",
      "251/251 [==============================] - 43s 170ms/step - loss: 1.4740 - accuracy: 0.5348 - val_loss: 1.5489 - val_accuracy: 0.5617\n",
      "Epoch 39/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.4878 - accuracy: 0.5281\n",
      "Epoch 00039: val_loss did not improve from 1.54885\n",
      "251/251 [==============================] - 42s 168ms/step - loss: 1.4878 - accuracy: 0.5281 - val_loss: 1.6041 - val_accuracy: 0.5597\n",
      "Epoch 40/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.4336 - accuracy: 0.5406\n",
      "Epoch 00040: val_loss improved from 1.54885 to 1.52225, saving model to model.h5\n",
      "251/251 [==============================] - 41s 162ms/step - loss: 1.4337 - accuracy: 0.5407 - val_loss: 1.5223 - val_accuracy: 0.5737\n",
      "Epoch 41/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.4077 - accuracy: 0.5418\n",
      "Epoch 00041: val_loss did not improve from 1.52225\n",
      "251/251 [==============================] - 41s 161ms/step - loss: 1.4077 - accuracy: 0.5418 - val_loss: 1.5434 - val_accuracy: 0.5857\n",
      "Epoch 42/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.3933 - accuracy: 0.5474\n",
      "Epoch 00042: val_loss did not improve from 1.52225\n",
      "251/251 [==============================] - 41s 163ms/step - loss: 1.3933 - accuracy: 0.5474 - val_loss: 1.5599 - val_accuracy: 0.5657\n",
      "Epoch 43/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.3324 - accuracy: 0.5700\n",
      "Epoch 00043: val_loss did not improve from 1.52225\n",
      "251/251 [==============================] - 42s 167ms/step - loss: 1.3324 - accuracy: 0.5700 - val_loss: 1.5838 - val_accuracy: 0.5692\n",
      "Epoch 44/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.3168 - accuracy: 0.5779\n",
      "Epoch 00044: val_loss did not improve from 1.52225\n",
      "251/251 [==============================] - 39s 155ms/step - loss: 1.3168 - accuracy: 0.5779 - val_loss: 1.5509 - val_accuracy: 0.5982\n",
      "Epoch 45/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.3256 - accuracy: 0.5770\n",
      "Epoch 00045: val_loss did not improve from 1.52225\n",
      "251/251 [==============================] - 37s 147ms/step - loss: 1.3256 - accuracy: 0.5770 - val_loss: 1.5309 - val_accuracy: 0.5872\n",
      "Epoch 46/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.2833 - accuracy: 0.5788\n",
      "Epoch 00046: val_loss did not improve from 1.52225\n",
      "251/251 [==============================] - 42s 168ms/step - loss: 1.2833 - accuracy: 0.5788 - val_loss: 1.5325 - val_accuracy: 0.5877\n",
      "Epoch 47/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.2616 - accuracy: 0.5885\n",
      "Epoch 00047: val_loss did not improve from 1.52225\n",
      "251/251 [==============================] - 41s 162ms/step - loss: 1.2616 - accuracy: 0.5885 - val_loss: 1.5313 - val_accuracy: 0.5932\n",
      "Epoch 48/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.2828 - accuracy: 0.5842\n",
      "Epoch 00048: val_loss improved from 1.52225 to 1.47513, saving model to model.h5\n",
      "251/251 [==============================] - 26s 102ms/step - loss: 1.2828 - accuracy: 0.5842 - val_loss: 1.4751 - val_accuracy: 0.5962\n",
      "Epoch 49/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.2431 - accuracy: 0.5975\n",
      "Epoch 00049: val_loss did not improve from 1.47513\n",
      "251/251 [==============================] - 23s 92ms/step - loss: 1.2431 - accuracy: 0.5974 - val_loss: 1.5047 - val_accuracy: 0.6037\n",
      "Epoch 50/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.2297 - accuracy: 0.6015\n",
      "Epoch 00050: val_loss did not improve from 1.47513\n",
      "251/251 [==============================] - 25s 98ms/step - loss: 1.2305 - accuracy: 0.6014 - val_loss: 1.4975 - val_accuracy: 0.5847\n",
      "Epoch 51/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.2124 - accuracy: 0.6064\n",
      "Epoch 00051: val_loss improved from 1.47513 to 1.47035, saving model to model.h5\n",
      "251/251 [==============================] - 27s 107ms/step - loss: 1.2127 - accuracy: 0.6061 - val_loss: 1.4703 - val_accuracy: 0.6142\n",
      "Epoch 52/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.2379 - accuracy: 0.5951\n",
      "Epoch 00052: val_loss did not improve from 1.47035\n",
      "251/251 [==============================] - 28s 112ms/step - loss: 1.2378 - accuracy: 0.5953 - val_loss: 1.5117 - val_accuracy: 0.5982\n",
      "Epoch 53/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.1640 - accuracy: 0.6192\n",
      "Epoch 00053: val_loss did not improve from 1.47035\n",
      "251/251 [==============================] - 28s 111ms/step - loss: 1.1639 - accuracy: 0.6193 - val_loss: 1.7232 - val_accuracy: 0.5767\n",
      "Epoch 54/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.2006 - accuracy: 0.6089\n",
      "Epoch 00054: val_loss did not improve from 1.47035\n",
      "251/251 [==============================] - 24s 97ms/step - loss: 1.2006 - accuracy: 0.6089 - val_loss: 1.5368 - val_accuracy: 0.6012\n",
      "Epoch 55/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.1541 - accuracy: 0.6215\n",
      "Epoch 00055: val_loss did not improve from 1.47035\n",
      "251/251 [==============================] - 23s 92ms/step - loss: 1.1544 - accuracy: 0.6214 - val_loss: 1.5209 - val_accuracy: 0.6107\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/251 [============================>.] - ETA: 0s - loss: 1.1245 - accuracy: 0.6335\n",
      "Epoch 00056: val_loss did not improve from 1.47035\n",
      "251/251 [==============================] - 25s 98ms/step - loss: 1.1247 - accuracy: 0.6335 - val_loss: 1.5550 - val_accuracy: 0.6067\n",
      "Epoch 57/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.1541 - accuracy: 0.6230\n",
      "Epoch 00057: val_loss did not improve from 1.47035\n",
      "251/251 [==============================] - 23s 93ms/step - loss: 1.1542 - accuracy: 0.6229 - val_loss: 1.5658 - val_accuracy: 0.6247\n",
      "Epoch 58/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.1561 - accuracy: 0.6220\n",
      "Epoch 00058: val_loss did not improve from 1.47035\n",
      "251/251 [==============================] - 23s 91ms/step - loss: 1.1562 - accuracy: 0.6219 - val_loss: 1.5224 - val_accuracy: 0.6062\n",
      "Epoch 59/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.1351 - accuracy: 0.6343\n",
      "Epoch 00059: val_loss did not improve from 1.47035\n",
      "251/251 [==============================] - 33s 132ms/step - loss: 1.1351 - accuracy: 0.6343 - val_loss: 1.5073 - val_accuracy: 0.6187\n",
      "Epoch 60/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.0873 - accuracy: 0.6424\n",
      "Epoch 00060: val_loss did not improve from 1.47035\n",
      "251/251 [==============================] - 31s 124ms/step - loss: 1.0872 - accuracy: 0.6424 - val_loss: 1.4776 - val_accuracy: 0.6312\n",
      "Epoch 61/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.0194 - accuracy: 0.6604\n",
      "Epoch 00061: val_loss did not improve from 1.47035\n",
      "251/251 [==============================] - 36s 142ms/step - loss: 1.0194 - accuracy: 0.6604 - val_loss: 1.5777 - val_accuracy: 0.6347\n",
      "Epoch 62/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.0158 - accuracy: 0.6665\n",
      "Epoch 00062: val_loss did not improve from 1.47035\n",
      "251/251 [==============================] - 44s 177ms/step - loss: 1.0158 - accuracy: 0.6665 - val_loss: 1.6328 - val_accuracy: 0.6142\n",
      "Epoch 63/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.0513 - accuracy: 0.6538\n",
      "Epoch 00063: val_loss did not improve from 1.47035\n",
      "251/251 [==============================] - 31s 125ms/step - loss: 1.0512 - accuracy: 0.6538 - val_loss: 1.5017 - val_accuracy: 0.6257\n",
      "Epoch 64/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.9701 - accuracy: 0.6793\n",
      "Epoch 00064: val_loss did not improve from 1.47035\n",
      "251/251 [==============================] - 27s 109ms/step - loss: 0.9699 - accuracy: 0.6794 - val_loss: 1.5477 - val_accuracy: 0.6417\n",
      "Epoch 65/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.1009 - accuracy: 0.6460\n",
      "Epoch 00065: val_loss did not improve from 1.47035\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 1.1010 - accuracy: 0.6459 - val_loss: 1.4792 - val_accuracy: 0.6252\n",
      "Epoch 66/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.0172 - accuracy: 0.6587\n",
      "Epoch 00066: val_loss did not improve from 1.47035\n",
      "251/251 [==============================] - 30s 118ms/step - loss: 1.0170 - accuracy: 0.6588 - val_loss: 1.5560 - val_accuracy: 0.6372\n",
      "Epoch 67/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.9788 - accuracy: 0.6741\n",
      "Epoch 00067: val_loss did not improve from 1.47035\n",
      "251/251 [==============================] - 22s 89ms/step - loss: 0.9789 - accuracy: 0.6741 - val_loss: 1.4987 - val_accuracy: 0.6517\n",
      "Epoch 68/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.9742 - accuracy: 0.6798\n",
      "Epoch 00068: val_loss did not improve from 1.47035\n",
      "251/251 [==============================] - 22s 89ms/step - loss: 0.9742 - accuracy: 0.6797 - val_loss: 1.5598 - val_accuracy: 0.6397\n",
      "Epoch 69/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.9502 - accuracy: 0.6834\n",
      "Epoch 00069: val_loss did not improve from 1.47035\n",
      "251/251 [==============================] - 22s 89ms/step - loss: 0.9499 - accuracy: 0.6835 - val_loss: 1.5739 - val_accuracy: 0.6452\n",
      "Epoch 70/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.9876 - accuracy: 0.6722\n",
      "Epoch 00070: val_loss did not improve from 1.47035\n",
      "251/251 [==============================] - 23s 90ms/step - loss: 0.9872 - accuracy: 0.6724 - val_loss: 1.5619 - val_accuracy: 0.6432\n",
      "Epoch 71/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.9346 - accuracy: 0.6866\n",
      "Epoch 00071: val_loss did not improve from 1.47035\n",
      "251/251 [==============================] - 22s 89ms/step - loss: 0.9345 - accuracy: 0.6866 - val_loss: 1.6944 - val_accuracy: 0.6357\n",
      "Epoch 72/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.9297 - accuracy: 0.6930\n",
      "Epoch 00072: val_loss did not improve from 1.47035\n",
      "251/251 [==============================] - 22s 89ms/step - loss: 0.9295 - accuracy: 0.6930 - val_loss: 1.5026 - val_accuracy: 0.6532\n",
      "Epoch 73/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.8860 - accuracy: 0.7044\n",
      "Epoch 00073: val_loss did not improve from 1.47035\n",
      "251/251 [==============================] - 22s 89ms/step - loss: 0.8859 - accuracy: 0.7045 - val_loss: 1.5553 - val_accuracy: 0.6477\n",
      "Epoch 74/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.8546 - accuracy: 0.7090\n",
      "Epoch 00074: val_loss did not improve from 1.47035\n",
      "251/251 [==============================] - 22s 89ms/step - loss: 0.8547 - accuracy: 0.7090 - val_loss: 1.7056 - val_accuracy: 0.6502\n",
      "Epoch 75/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.9324 - accuracy: 0.6861\n",
      "Epoch 00075: val_loss did not improve from 1.47035\n",
      "251/251 [==============================] - 22s 89ms/step - loss: 0.9325 - accuracy: 0.6860 - val_loss: 1.5975 - val_accuracy: 0.6427\n",
      "Epoch 76/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.8630 - accuracy: 0.7104\n",
      "Epoch 00076: val_loss did not improve from 1.47035\n",
      "251/251 [==============================] - 27s 108ms/step - loss: 0.8630 - accuracy: 0.7104 - val_loss: 1.6073 - val_accuracy: 0.6567\n",
      "Epoch 77/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.8770 - accuracy: 0.7051\n",
      "Epoch 00077: val_loss did not improve from 1.47035\n",
      "251/251 [==============================] - 27s 109ms/step - loss: 0.8770 - accuracy: 0.7051 - val_loss: 1.6431 - val_accuracy: 0.6532\n",
      "Epoch 78/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.8560 - accuracy: 0.7089\n",
      "Epoch 00078: val_loss did not improve from 1.47035\n",
      "251/251 [==============================] - 28s 110ms/step - loss: 0.8560 - accuracy: 0.7089 - val_loss: 1.5997 - val_accuracy: 0.6537\n",
      "Epoch 79/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.8641 - accuracy: 0.7081\n",
      "Epoch 00079: val_loss did not improve from 1.47035\n",
      "251/251 [==============================] - 28s 110ms/step - loss: 0.8641 - accuracy: 0.7081 - val_loss: 1.5131 - val_accuracy: 0.6602\n",
      "Epoch 80/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.8304 - accuracy: 0.7165\n",
      "Epoch 00080: val_loss did not improve from 1.47035\n",
      "251/251 [==============================] - 28s 110ms/step - loss: 0.8304 - accuracy: 0.7165 - val_loss: 1.6747 - val_accuracy: 0.6562\n",
      "Epoch 81/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.8237 - accuracy: 0.7269\n",
      "Epoch 00081: val_loss did not improve from 1.47035\n",
      "251/251 [==============================] - 28s 110ms/step - loss: 0.8237 - accuracy: 0.7269 - val_loss: 1.6330 - val_accuracy: 0.6602\n",
      "Epoch 82/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.8239 - accuracy: 0.7246\n",
      "Epoch 00082: val_loss did not improve from 1.47035\n",
      "251/251 [==============================] - 28s 112ms/step - loss: 0.8239 - accuracy: 0.7246 - val_loss: 1.6481 - val_accuracy: 0.6627\n",
      "Epoch 83/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.8478 - accuracy: 0.7176\n",
      "Epoch 00083: val_loss did not improve from 1.47035\n",
      "251/251 [==============================] - 28s 110ms/step - loss: 0.8478 - accuracy: 0.7176 - val_loss: 1.6536 - val_accuracy: 0.6622\n",
      "Epoch 84/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.7902 - accuracy: 0.7302\n",
      "Epoch 00084: val_loss did not improve from 1.47035\n",
      "251/251 [==============================] - 28s 110ms/step - loss: 0.7902 - accuracy: 0.7302 - val_loss: 1.6115 - val_accuracy: 0.6717\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/251 [============================>.] - ETA: 0s - loss: 0.7700 - accuracy: 0.7398\n",
      "Epoch 00085: val_loss did not improve from 1.47035\n",
      "251/251 [==============================] - 26s 102ms/step - loss: 0.7698 - accuracy: 0.7398 - val_loss: 1.7245 - val_accuracy: 0.6712\n",
      "Epoch 86/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.7938 - accuracy: 0.7293\n",
      "Epoch 00086: val_loss did not improve from 1.47035\n",
      "251/251 [==============================] - 26s 102ms/step - loss: 0.7939 - accuracy: 0.7291 - val_loss: 1.6741 - val_accuracy: 0.6632\n",
      "Epoch 87/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.8106 - accuracy: 0.7311\n",
      "Epoch 00087: val_loss did not improve from 1.47035\n",
      "251/251 [==============================] - 26s 103ms/step - loss: 0.8104 - accuracy: 0.7312 - val_loss: 1.6221 - val_accuracy: 0.6597\n",
      "Epoch 88/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.7570 - accuracy: 0.7386\n",
      "Epoch 00088: val_loss did not improve from 1.47035\n",
      "251/251 [==============================] - 26s 102ms/step - loss: 0.7570 - accuracy: 0.7386 - val_loss: 1.6681 - val_accuracy: 0.6677\n",
      "Epoch 89/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.7953 - accuracy: 0.7360\n",
      "Epoch 00089: val_loss did not improve from 1.47035\n",
      "251/251 [==============================] - 26s 102ms/step - loss: 0.7955 - accuracy: 0.7360 - val_loss: 1.6818 - val_accuracy: 0.6602\n",
      "Epoch 90/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.7630 - accuracy: 0.7441\n",
      "Epoch 00090: val_loss did not improve from 1.47035\n",
      "251/251 [==============================] - 26s 102ms/step - loss: 0.7630 - accuracy: 0.7441 - val_loss: 1.6890 - val_accuracy: 0.6682\n",
      "Epoch 91/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.7548 - accuracy: 0.7373\n",
      "Epoch 00091: val_loss did not improve from 1.47035\n",
      "251/251 [==============================] - 26s 105ms/step - loss: 0.7548 - accuracy: 0.7373 - val_loss: 1.6793 - val_accuracy: 0.6532\n",
      "Epoch 92/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.7248 - accuracy: 0.7535\n",
      "Epoch 00092: val_loss did not improve from 1.47035\n",
      "251/251 [==============================] - 33s 131ms/step - loss: 0.7248 - accuracy: 0.7535 - val_loss: 1.7511 - val_accuracy: 0.6662\n",
      "Epoch 93/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.7258 - accuracy: 0.7514\n",
      "Epoch 00093: val_loss did not improve from 1.47035\n",
      "251/251 [==============================] - 33s 130ms/step - loss: 0.7256 - accuracy: 0.7515 - val_loss: 1.7620 - val_accuracy: 0.6582\n",
      "Epoch 94/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.7029 - accuracy: 0.7599\n",
      "Epoch 00094: val_loss did not improve from 1.47035\n",
      "251/251 [==============================] - 32s 128ms/step - loss: 0.7031 - accuracy: 0.7597 - val_loss: 1.7846 - val_accuracy: 0.6617\n",
      "Epoch 95/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.7322 - accuracy: 0.7490\n",
      "Epoch 00095: val_loss did not improve from 1.47035\n",
      "251/251 [==============================] - 32s 129ms/step - loss: 0.7322 - accuracy: 0.7490 - val_loss: 1.7761 - val_accuracy: 0.6742\n",
      "Epoch 96/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.6708 - accuracy: 0.7701\n",
      "Epoch 00096: val_loss did not improve from 1.47035\n",
      "251/251 [==============================] - 25s 101ms/step - loss: 0.6706 - accuracy: 0.7702 - val_loss: 1.7589 - val_accuracy: 0.6807\n",
      "Epoch 97/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.6624 - accuracy: 0.7676\n",
      "Epoch 00097: val_loss did not improve from 1.47035\n",
      "251/251 [==============================] - 22s 89ms/step - loss: 0.6624 - accuracy: 0.7676 - val_loss: 1.9200 - val_accuracy: 0.6647\n",
      "Epoch 98/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.8454 - accuracy: 0.7247\n",
      "Epoch 00098: val_loss did not improve from 1.47035\n",
      "251/251 [==============================] - 22s 89ms/step - loss: 0.8453 - accuracy: 0.7249 - val_loss: 1.5800 - val_accuracy: 0.6552\n",
      "Epoch 99/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.7694 - accuracy: 0.7418\n",
      "Epoch 00099: val_loss did not improve from 1.47035\n",
      "251/251 [==============================] - 33s 133ms/step - loss: 0.7694 - accuracy: 0.7418 - val_loss: 1.7003 - val_accuracy: 0.6607\n",
      "Epoch 100/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.7005 - accuracy: 0.7565\n",
      "Epoch 00100: val_loss did not improve from 1.47035\n",
      "251/251 [==============================] - 37s 147ms/step - loss: 0.7005 - accuracy: 0.7565 - val_loss: 1.8107 - val_accuracy: 0.6732\n"
     ]
    }
   ],
   "source": [
    "filename = 'model.h5'\n",
    "checkpoint = ModelCheckpoint(filename,\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             mode='min')\n",
    "\n",
    "hist = model_lstm.fit(train_X, train_Y,\n",
    "                 epochs = 100,\n",
    "                 batch_size = 32,\n",
    "                 validation_data = (val_X, val_Y),\n",
    "                 callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YjXKos8ocXvw"
   },
   "outputs": [],
   "source": [
    "model_lstm = load_model(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qSTEzrlzcuya"
   },
   "outputs": [],
   "source": [
    "def predictions(text):\n",
    "  clean = re.sub(r'[^ a-z A-Z 0-9]', \" \", text)\n",
    "  test_word = word_tokenize(clean)\n",
    "  test_word = [w.lower() for w in test_word]\n",
    "  test_ls = word_tokenizer.texts_to_sequences(test_word)\n",
    "#   print(test_ls)\n",
    "#   print(test_word)\n",
    "\n",
    "  #Check for unknown words\n",
    "  if [] in test_ls:\n",
    "    test_ls = list(filter(None, test_ls))\n",
    "    \n",
    "  test_ls = np.array(test_ls).reshape(1, len(test_ls))\n",
    "  x = padding_doc(test_ls, max_length)\n",
    "    \n",
    "#   print(x)\n",
    "\n",
    "  pred = model_lstm.predict(x)\n",
    "  \n",
    "  return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P1ddofshmdzK"
   },
   "outputs": [],
   "source": [
    "def get_final_output(pred, classes):\n",
    "  predictions = pred[0]\n",
    "#   print(predictions)\n",
    "#   classes = np.array(classes)\n",
    "  print(classes)\n",
    "  ids = np.argsort(-predictions)\n",
    "#   classes = classes[ids]\n",
    "  print(classes)\n",
    "  predictions = -np.sort(-predictions)\n",
    " \n",
    "  for i in range(pred.shape[1]):\n",
    "    print(\"%s has confidence = %s\" % (classes[i], (predictions[i])))\n",
    "  \n",
    "  return classes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "23VpGuihMdEU",
    "outputId": "cd36c932-0fb0-4166-92ae-546a7676e645"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['exchange_rate', 'contactless_not_working', 'declined_cash_withdrawal', 'card_arrival', 'card_payment_fee_charged', 'wrong_exchange_rate_for_cash_withdrawal', 'why_verify_identity', 'passcode_forgotten', 'cash_withdrawal_charge', 'top_up_limits', 'balance_not_updated_after_cheque_or_cash_deposit', 'transfer_timing', 'balance_not_updated_after_bank_transfer', 'card_payment_not_recognised', 'failed_transfer', 'transaction_charged_twice', 'order_physical_card', 'wrong_amount_of_cash_received', 'card_not_working', 'pending_transfer', 'direct_debit_payment_not_recognised', 'getting_virtual_card', 'edit_personal_details', 'compromised_card', 'transfer_fee_charged', 'verify_my_identity', 'country_support', 'top_up_by_card_charge', 'Refund_not_showing_up', 'cancel_transfer', 'get_physical_card', 'receiving_money', 'card_swallowed', 'age_limit', 'extra_charge_on_statement', 'disposable_card_limits', 'change_pin', 'declined_card_payment', 'card_delivery_estimate', 'reverted_card_payment?', 'card_payment_wrong_exchange_rate', 'get_disposable_virtual_card', 'terminate_account', 'pending_cash_withdrawal', 'top_up_reverted', 'transfer_not_received_by_recipient', 'supported_cards_and_currencies', 'lost_or_stolen_phone', 'category', 'exchange_via_app', 'atm_support', 'pending_card_payment', 'exchange_charge', 'lost_or_stolen_card', 'unable_to_verify_identity', 'getting_spare_card', 'virtual_card_not_working', 'cash_withdrawal_not_recognised', 'declined_transfer', 'top_up_by_cash_or_cheque', 'apple_pay_or_google_pay', 'visa_or_mastercard', 'beneficiary_not_allowed', 'activate_my_card', 'pending_top_up', 'transfer_into_account', 'card_about_to_expire', 'top_up_failed', 'pin_blocked', 'verify_top_up', 'request_refund', 'card_linking', 'automatic_top_up', 'top_up_by_bank_transfer_charge', 'verify_source_of_funds', 'topping_up_by_card', 'card_acceptance', 'fiat_currency_support']\n",
      "['exchange_rate', 'contactless_not_working', 'declined_cash_withdrawal', 'card_arrival', 'card_payment_fee_charged', 'wrong_exchange_rate_for_cash_withdrawal', 'why_verify_identity', 'passcode_forgotten', 'cash_withdrawal_charge', 'top_up_limits', 'balance_not_updated_after_cheque_or_cash_deposit', 'transfer_timing', 'balance_not_updated_after_bank_transfer', 'card_payment_not_recognised', 'failed_transfer', 'transaction_charged_twice', 'order_physical_card', 'wrong_amount_of_cash_received', 'card_not_working', 'pending_transfer', 'direct_debit_payment_not_recognised', 'getting_virtual_card', 'edit_personal_details', 'compromised_card', 'transfer_fee_charged', 'verify_my_identity', 'country_support', 'top_up_by_card_charge', 'Refund_not_showing_up', 'cancel_transfer', 'get_physical_card', 'receiving_money', 'card_swallowed', 'age_limit', 'extra_charge_on_statement', 'disposable_card_limits', 'change_pin', 'declined_card_payment', 'card_delivery_estimate', 'reverted_card_payment?', 'card_payment_wrong_exchange_rate', 'get_disposable_virtual_card', 'terminate_account', 'pending_cash_withdrawal', 'top_up_reverted', 'transfer_not_received_by_recipient', 'supported_cards_and_currencies', 'lost_or_stolen_phone', 'category', 'exchange_via_app', 'atm_support', 'pending_card_payment', 'exchange_charge', 'lost_or_stolen_card', 'unable_to_verify_identity', 'getting_spare_card', 'virtual_card_not_working', 'cash_withdrawal_not_recognised', 'declined_transfer', 'top_up_by_cash_or_cheque', 'apple_pay_or_google_pay', 'visa_or_mastercard', 'beneficiary_not_allowed', 'activate_my_card', 'pending_top_up', 'transfer_into_account', 'card_about_to_expire', 'top_up_failed', 'pin_blocked', 'verify_top_up', 'request_refund', 'card_linking', 'automatic_top_up', 'top_up_by_bank_transfer_charge', 'verify_source_of_funds', 'topping_up_by_card', 'card_acceptance', 'fiat_currency_support']\n",
      "exchange_rate has confidence = 0.388203\n",
      "contactless_not_working has confidence = 0.2828172\n",
      "declined_cash_withdrawal has confidence = 0.10544735\n",
      "card_arrival has confidence = 0.05497793\n",
      "card_payment_fee_charged has confidence = 0.044158656\n",
      "wrong_exchange_rate_for_cash_withdrawal has confidence = 0.03831381\n",
      "why_verify_identity has confidence = 0.0148200765\n",
      "passcode_forgotten has confidence = 0.013619259\n",
      "cash_withdrawal_charge has confidence = 0.010870798\n",
      "top_up_limits has confidence = 0.010216601\n",
      "balance_not_updated_after_cheque_or_cash_deposit has confidence = 0.009105929\n",
      "transfer_timing has confidence = 0.007043392\n",
      "balance_not_updated_after_bank_transfer has confidence = 0.004485206\n",
      "card_payment_not_recognised has confidence = 0.004468125\n",
      "failed_transfer has confidence = 0.0038785327\n",
      "transaction_charged_twice has confidence = 0.0020097475\n",
      "order_physical_card has confidence = 0.0011436713\n",
      "wrong_amount_of_cash_received has confidence = 0.00084258296\n",
      "card_not_working has confidence = 0.0007778044\n",
      "pending_transfer has confidence = 0.00037651244\n",
      "direct_debit_payment_not_recognised has confidence = 0.00028464865\n",
      "getting_virtual_card has confidence = 0.00024930754\n",
      "edit_personal_details has confidence = 0.0002402179\n",
      "compromised_card has confidence = 0.00022872793\n",
      "transfer_fee_charged has confidence = 0.00021320276\n",
      "verify_my_identity has confidence = 0.00015831574\n",
      "country_support has confidence = 0.0001275453\n",
      "top_up_by_card_charge has confidence = 0.000112923575\n",
      "Refund_not_showing_up has confidence = 9.3476425e-05\n",
      "cancel_transfer has confidence = 7.978111e-05\n",
      "get_physical_card has confidence = 7.936987e-05\n",
      "receiving_money has confidence = 7.081243e-05\n",
      "card_swallowed has confidence = 6.9143105e-05\n",
      "age_limit has confidence = 6.410678e-05\n",
      "extra_charge_on_statement has confidence = 5.8417165e-05\n",
      "disposable_card_limits has confidence = 5.161889e-05\n",
      "change_pin has confidence = 4.8570604e-05\n",
      "declined_card_payment has confidence = 3.677665e-05\n",
      "card_delivery_estimate has confidence = 3.254498e-05\n",
      "reverted_card_payment? has confidence = 1.5222484e-05\n",
      "card_payment_wrong_exchange_rate has confidence = 1.4111147e-05\n",
      "get_disposable_virtual_card has confidence = 1.3968804e-05\n",
      "terminate_account has confidence = 1.2788762e-05\n",
      "pending_cash_withdrawal has confidence = 1.2633442e-05\n",
      "top_up_reverted has confidence = 8.007759e-06\n",
      "transfer_not_received_by_recipient has confidence = 7.0643696e-06\n",
      "supported_cards_and_currencies has confidence = 6.805021e-06\n",
      "lost_or_stolen_phone has confidence = 5.7636207e-06\n",
      "category has confidence = 5.47768e-06\n",
      "exchange_via_app has confidence = 4.692897e-06\n",
      "atm_support has confidence = 3.3496876e-06\n",
      "pending_card_payment has confidence = 3.142365e-06\n",
      "exchange_charge has confidence = 2.27504e-06\n",
      "lost_or_stolen_card has confidence = 2.0953873e-06\n",
      "unable_to_verify_identity has confidence = 1.6219672e-06\n",
      "getting_spare_card has confidence = 1.5817341e-06\n",
      "virtual_card_not_working has confidence = 1.2183998e-06\n",
      "cash_withdrawal_not_recognised has confidence = 6.209348e-07\n",
      "declined_transfer has confidence = 4.0194544e-07\n",
      "top_up_by_cash_or_cheque has confidence = 3.3057705e-07\n",
      "apple_pay_or_google_pay has confidence = 2.8524903e-07\n",
      "visa_or_mastercard has confidence = 2.2811807e-07\n",
      "beneficiary_not_allowed has confidence = 1.1925746e-07\n",
      "activate_my_card has confidence = 7.638907e-08\n",
      "pending_top_up has confidence = 7.295355e-08\n",
      "transfer_into_account has confidence = 6.592595e-08\n",
      "card_about_to_expire has confidence = 6.458114e-08\n",
      "top_up_failed has confidence = 6.208445e-08\n",
      "pin_blocked has confidence = 5.8263574e-08\n",
      "verify_top_up has confidence = 3.8958202e-08\n",
      "request_refund has confidence = 2.9298132e-08\n",
      "card_linking has confidence = 1.7530855e-08\n",
      "automatic_top_up has confidence = 4.8085464e-09\n",
      "top_up_by_bank_transfer_charge has confidence = 4.24786e-09\n",
      "verify_source_of_funds has confidence = 1.7479763e-09\n",
      "topping_up_by_card has confidence = 6.7103306e-10\n",
      "card_acceptance has confidence = 2.7373395e-10\n",
      "fiat_currency_support has confidence = 9.198665e-11\n",
      "\n",
      "ans: exchange_rate\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = \"I am still waiting on my card?\"\n",
    "pred = predictions(text)\n",
    "result = get_final_output(pred, unique_intent)\n",
    "print('\\nans: {}\\n'.format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['exchange_rate' 'contactless_not_working' 'declined_cash_withdrawal'\n",
      " 'card_arrival' 'card_payment_fee_charged'\n",
      " 'wrong_exchange_rate_for_cash_withdrawal' 'why_verify_identity'\n",
      " 'passcode_forgotten' 'cash_withdrawal_charge' 'top_up_limits'\n",
      " 'balance_not_updated_after_cheque_or_cash_deposit' 'transfer_timing'\n",
      " 'balance_not_updated_after_bank_transfer' 'card_payment_not_recognised'\n",
      " 'failed_transfer' 'transaction_charged_twice' 'order_physical_card'\n",
      " 'wrong_amount_of_cash_received' 'card_not_working' 'pending_transfer'\n",
      " 'direct_debit_payment_not_recognised' 'getting_virtual_card'\n",
      " 'edit_personal_details' 'compromised_card' 'transfer_fee_charged'\n",
      " 'verify_my_identity' 'country_support' 'top_up_by_card_charge'\n",
      " 'Refund_not_showing_up' 'cancel_transfer' 'get_physical_card'\n",
      " 'receiving_money' 'card_swallowed' 'age_limit'\n",
      " 'extra_charge_on_statement' 'disposable_card_limits' 'change_pin'\n",
      " 'declined_card_payment' 'card_delivery_estimate' 'reverted_card_payment?'\n",
      " 'card_payment_wrong_exchange_rate' 'get_disposable_virtual_card'\n",
      " 'terminate_account' 'pending_cash_withdrawal' 'top_up_reverted'\n",
      " 'transfer_not_received_by_recipient' 'supported_cards_and_currencies'\n",
      " 'lost_or_stolen_phone' 'category' 'exchange_via_app' 'atm_support'\n",
      " 'pending_card_payment' 'exchange_charge' 'lost_or_stolen_card'\n",
      " 'unable_to_verify_identity' 'getting_spare_card'\n",
      " 'virtual_card_not_working' 'cash_withdrawal_not_recognised'\n",
      " 'declined_transfer' 'top_up_by_cash_or_cheque' 'apple_pay_or_google_pay'\n",
      " 'visa_or_mastercard' 'beneficiary_not_allowed' 'activate_my_card'\n",
      " 'pending_top_up' 'transfer_into_account' 'card_about_to_expire'\n",
      " 'top_up_failed' 'pin_blocked' 'verify_top_up' 'request_refund'\n",
      " 'card_linking' 'automatic_top_up' 'top_up_by_bank_transfer_charge'\n",
      " 'verify_source_of_funds' 'topping_up_by_card' 'card_acceptance'\n",
      " 'fiat_currency_support']\n",
      "['exchange_rate' 'fiat_currency_support'\n",
      " 'card_payment_wrong_exchange_rate' 'exchange_charge' 'exchange_via_app'\n",
      " 'supported_cards_and_currencies' 'automatic_top_up'\n",
      " 'wrong_exchange_rate_for_cash_withdrawal' 'verify_source_of_funds'\n",
      " 'top_up_by_bank_transfer_charge' 'receiving_money'\n",
      " 'top_up_by_cash_or_cheque' 'transfer_into_account'\n",
      " 'wrong_amount_of_cash_received' 'country_support' 'atm_support'\n",
      " 'age_limit' 'visa_or_mastercard' 'edit_personal_details'\n",
      " 'why_verify_identity' 'top_up_limits' 'topping_up_by_card'\n",
      " 'top_up_by_card_charge' 'declined_cash_withdrawal'\n",
      " 'beneficiary_not_allowed' 'transfer_timing'\n",
      " 'balance_not_updated_after_bank_transfer' 'unable_to_verify_identity'\n",
      " 'verify_my_identity' 'cash_withdrawal_charge' 'change_pin'\n",
      " 'pending_top_up' 'balance_not_updated_after_cheque_or_cash_deposit'\n",
      " 'apple_pay_or_google_pay' 'top_up_reverted'\n",
      " 'transfer_not_received_by_recipient' 'transfer_fee_charged'\n",
      " 'request_refund' 'card_acceptance' 'cancel_transfer'\n",
      " 'cash_withdrawal_not_recognised' 'pending_cash_withdrawal' 'pin_blocked'\n",
      " 'terminate_account' 'transaction_charged_twice' 'card_delivery_estimate'\n",
      " 'card_payment_fee_charged' 'compromised_card' 'top_up_failed'\n",
      " 'passcode_forgotten' 'card_swallowed' 'category' 'verify_top_up'\n",
      " 'getting_spare_card' 'declined_transfer' 'disposable_card_limits'\n",
      " 'card_about_to_expire' 'card_not_working' 'order_physical_card'\n",
      " 'failed_transfer' 'pending_transfer'\n",
      " 'direct_debit_payment_not_recognised' 'lost_or_stolen_phone'\n",
      " 'Refund_not_showing_up' 'get_physical_card' 'contactless_not_working'\n",
      " 'activate_my_card' 'get_disposable_virtual_card' 'reverted_card_payment?'\n",
      " 'card_arrival' 'getting_virtual_card' 'lost_or_stolen_card'\n",
      " 'extra_charge_on_statement' 'card_linking' 'card_payment_not_recognised'\n",
      " 'pending_card_payment' 'declined_card_payment' 'virtual_card_not_working']\n",
      "exchange_rate has confidence = 0.99568826\n",
      "fiat_currency_support has confidence = 0.0020600427\n",
      "card_payment_wrong_exchange_rate has confidence = 0.0007059075\n",
      "exchange_charge has confidence = 0.00044949\n",
      "exchange_via_app has confidence = 0.00043904345\n",
      "supported_cards_and_currencies has confidence = 0.00037469165\n",
      "automatic_top_up has confidence = 0.00014319515\n",
      "wrong_exchange_rate_for_cash_withdrawal has confidence = 6.349546e-05\n",
      "verify_source_of_funds has confidence = 3.964243e-05\n",
      "top_up_by_bank_transfer_charge has confidence = 2.3390774e-05\n",
      "receiving_money has confidence = 9.816018e-06\n",
      "top_up_by_cash_or_cheque has confidence = 2.6036785e-06\n",
      "transfer_into_account has confidence = 3.3181928e-07\n",
      "wrong_amount_of_cash_received has confidence = 1.0008942e-07\n",
      "country_support has confidence = 3.2529005e-08\n",
      "atm_support has confidence = 2.884979e-08\n",
      "age_limit has confidence = 7.880087e-09\n",
      "visa_or_mastercard has confidence = 7.676242e-09\n",
      "edit_personal_details has confidence = 4.454245e-11\n",
      "why_verify_identity has confidence = 2.3783083e-11\n",
      "top_up_limits has confidence = 1.3222694e-11\n",
      "topping_up_by_card has confidence = 7.497638e-12\n",
      "top_up_by_card_charge has confidence = 6.2572387e-12\n",
      "declined_cash_withdrawal has confidence = 1.7460507e-12\n",
      "beneficiary_not_allowed has confidence = 2.0024822e-13\n",
      "transfer_timing has confidence = 1.6017215e-13\n",
      "balance_not_updated_after_bank_transfer has confidence = 1.0819944e-13\n",
      "unable_to_verify_identity has confidence = 2.9932643e-14\n",
      "verify_my_identity has confidence = 1.5170282e-14\n",
      "cash_withdrawal_charge has confidence = 3.370105e-15\n",
      "change_pin has confidence = 2.0260539e-15\n",
      "pending_top_up has confidence = 1.2086352e-16\n",
      "balance_not_updated_after_cheque_or_cash_deposit has confidence = 5.4488468e-17\n",
      "apple_pay_or_google_pay has confidence = 4.2240564e-17\n",
      "top_up_reverted has confidence = 2.5372475e-17\n",
      "transfer_not_received_by_recipient has confidence = 1.691216e-17\n",
      "transfer_fee_charged has confidence = 1.2677741e-17\n",
      "request_refund has confidence = 7.5638164e-18\n",
      "card_acceptance has confidence = 1.9110906e-18\n",
      "cancel_transfer has confidence = 4.7176664e-19\n",
      "cash_withdrawal_not_recognised has confidence = 1.5393866e-19\n",
      "pending_cash_withdrawal has confidence = 1.2155968e-19\n",
      "pin_blocked has confidence = 8.405174e-20\n",
      "terminate_account has confidence = 6.7384356e-20\n",
      "transaction_charged_twice has confidence = 3.435766e-20\n",
      "card_delivery_estimate has confidence = 3.2309048e-20\n",
      "card_payment_fee_charged has confidence = 4.05772e-21\n",
      "compromised_card has confidence = 1.6779491e-21\n",
      "top_up_failed has confidence = 1.6073338e-21\n",
      "passcode_forgotten has confidence = 9.006185e-22\n",
      "card_swallowed has confidence = 8.680244e-23\n",
      "category has confidence = 5.0724592e-23\n",
      "verify_top_up has confidence = 4.1468966e-23\n",
      "getting_spare_card has confidence = 1.8607152e-23\n",
      "declined_transfer has confidence = 1.7110354e-23\n",
      "disposable_card_limits has confidence = 1.0985871e-24\n",
      "card_about_to_expire has confidence = 1.1735461e-25\n",
      "card_not_working has confidence = 6.8078135e-26\n",
      "order_physical_card has confidence = 2.8571125e-26\n",
      "failed_transfer has confidence = 1.17727614e-26\n",
      "pending_transfer has confidence = 1.32100835e-27\n",
      "direct_debit_payment_not_recognised has confidence = 5.550096e-29\n",
      "lost_or_stolen_phone has confidence = 2.8060504e-29\n",
      "Refund_not_showing_up has confidence = 2.4943526e-30\n",
      "get_physical_card has confidence = 2.1240478e-30\n",
      "contactless_not_working has confidence = 1.10846785e-30\n",
      "activate_my_card has confidence = 7.0521964e-31\n",
      "get_disposable_virtual_card has confidence = 2.2207148e-31\n",
      "reverted_card_payment? has confidence = 5.9966134e-32\n",
      "card_arrival has confidence = 7.0723405e-33\n",
      "getting_virtual_card has confidence = 2.0352146e-33\n",
      "lost_or_stolen_card has confidence = 4.1976743e-35\n",
      "extra_charge_on_statement has confidence = 0.0\n",
      "card_linking has confidence = 0.0\n",
      "card_payment_not_recognised has confidence = 0.0\n",
      "pending_card_payment has confidence = 0.0\n",
      "declined_card_payment has confidence = 0.0\n",
      "virtual_card_not_working has confidence = 0.0\n",
      "\n",
      "ans: exchange_rate\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = \"What are you exchange rates?\"\n",
    "pred = predictions(text)\n",
    "result = get_final_output(pred, unique_intent)\n",
    "print('\\nans: {}\\n'.format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.68574754e-08 2.12975169e-06 8.40245828e-09 3.31459451e-05\n",
      " 3.42865940e-04 4.03943459e-12 1.37701918e-05 3.27244343e-05\n",
      " 1.45530155e-09 2.52635232e-07 6.97103887e-13 2.16613251e-12\n",
      " 3.84167497e-13 1.27918232e-09 6.49560938e-15 1.59837746e-05\n",
      " 3.70345898e-02 9.96490890e-09 1.40293298e-04 1.00660432e-15\n",
      " 3.02277294e-06 8.45013983e-06 6.04324555e-07 1.29024178e-04\n",
      " 3.59036392e-08 1.58564835e-05 6.20960474e-01 3.88364249e-04\n",
      " 3.99802969e-11 2.23928168e-10 1.97922236e-06 8.13702180e-04\n",
      " 8.84996371e-06 1.43649158e-04 4.01189010e-13 6.90123183e-04\n",
      " 6.08214259e-06 1.30175504e-09 2.09563458e-03 7.51939755e-09\n",
      " 4.34584209e-11 1.22867408e-04 1.88848692e-09 9.82983429e-14\n",
      " 3.83557812e-12 2.15759823e-11 1.49969244e-02 1.72874443e-05\n",
      " 7.08852724e-07 2.70885698e-06 7.95975886e-03 1.36375767e-15\n",
      " 2.34348554e-05 5.96944068e-04 6.87555166e-06 1.95589080e-01\n",
      " 8.23511659e-09 6.22206642e-08 9.16009889e-12 1.01916817e-06\n",
      " 2.49001982e-06 9.84833315e-02 7.83610599e-09 1.01847836e-04\n",
      " 7.77225576e-11 9.25913998e-11 6.42568152e-03 4.62279779e-08\n",
      " 2.33202609e-05 1.16853892e-06 2.07532812e-05 1.83398326e-04\n",
      " 4.00939903e-08 8.73757926e-06 1.32968021e-03 1.97567124e-06\n",
      " 1.12163546e-02 1.90166145e-06]\n",
      "country_support has confidence = 0.6209605\n",
      "getting_spare_card has confidence = 0.19558908\n",
      "visa_or_mastercard has confidence = 0.09848333\n",
      "order_physical_card has confidence = 0.03703459\n",
      "supported_cards_and_currencies has confidence = 0.014996924\n",
      "card_acceptance has confidence = 0.011216355\n",
      "atm_support has confidence = 0.007959759\n",
      "card_about_to_expire has confidence = 0.0064256815\n",
      "card_delivery_estimate has confidence = 0.0020956346\n",
      "verify_source_of_funds has confidence = 0.0013296802\n",
      "receiving_money has confidence = 0.0008137022\n",
      "disposable_card_limits has confidence = 0.0006901232\n",
      "lost_or_stolen_card has confidence = 0.00059694407\n",
      "top_up_by_card_charge has confidence = 0.00038836425\n",
      "card_payment_fee_charged has confidence = 0.00034286594\n",
      "card_linking has confidence = 0.00018339833\n",
      "age_limit has confidence = 0.00014364916\n",
      "card_not_working has confidence = 0.0001402933\n",
      "compromised_card has confidence = 0.00012902418\n",
      "get_disposable_virtual_card has confidence = 0.00012286741\n",
      "activate_my_card has confidence = 0.000101847836\n",
      "card_arrival has confidence = 3.3145945e-05\n",
      "passcode_forgotten has confidence = 3.2724434e-05\n",
      "exchange_charge has confidence = 2.3434855e-05\n",
      "pin_blocked has confidence = 2.332026e-05\n",
      "request_refund has confidence = 2.0753281e-05\n",
      "lost_or_stolen_phone has confidence = 1.7287444e-05\n",
      "transaction_charged_twice has confidence = 1.5983775e-05\n",
      "verify_my_identity has confidence = 1.5856484e-05\n",
      "why_verify_identity has confidence = 1.3770192e-05\n",
      "card_swallowed has confidence = 8.849964e-06\n",
      "top_up_by_bank_transfer_charge has confidence = 8.737579e-06\n",
      "getting_virtual_card has confidence = 8.45014e-06\n",
      "unable_to_verify_identity has confidence = 6.8755517e-06\n",
      "change_pin has confidence = 6.0821426e-06\n",
      "direct_debit_payment_not_recognised has confidence = 3.022773e-06\n",
      "exchange_via_app has confidence = 2.708857e-06\n",
      "apple_pay_or_google_pay has confidence = 2.4900198e-06\n",
      "contactless_not_working has confidence = 2.1297517e-06\n",
      "get_physical_card has confidence = 1.9792224e-06\n",
      "topping_up_by_card has confidence = 1.9756712e-06\n",
      "fiat_currency_support has confidence = 1.9016614e-06\n",
      "verify_top_up has confidence = 1.1685389e-06\n",
      "top_up_by_cash_or_cheque has confidence = 1.0191682e-06\n",
      "category has confidence = 7.088527e-07\n",
      "edit_personal_details has confidence = 6.0432455e-07\n",
      "top_up_limits has confidence = 2.5263523e-07\n",
      "cash_withdrawal_not_recognised has confidence = 6.2220664e-08\n",
      "top_up_failed has confidence = 4.6227978e-08\n",
      "automatic_top_up has confidence = 4.009399e-08\n",
      "transfer_fee_charged has confidence = 3.590364e-08\n",
      "exchange_rate has confidence = 1.6857475e-08\n",
      "wrong_amount_of_cash_received has confidence = 9.964909e-09\n",
      "declined_cash_withdrawal has confidence = 8.402458e-09\n",
      "virtual_card_not_working has confidence = 8.235117e-09\n",
      "beneficiary_not_allowed has confidence = 7.836106e-09\n",
      "reverted_card_payment? has confidence = 7.5193975e-09\n",
      "terminate_account has confidence = 1.888487e-09\n",
      "cash_withdrawal_charge has confidence = 1.4553015e-09\n",
      "declined_card_payment has confidence = 1.301755e-09\n",
      "card_payment_not_recognised has confidence = 1.2791823e-09\n",
      "cancel_transfer has confidence = 2.2392817e-10\n",
      "transfer_into_account has confidence = 9.25914e-11\n",
      "pending_top_up has confidence = 7.772256e-11\n",
      "card_payment_wrong_exchange_rate has confidence = 4.345842e-11\n",
      "Refund_not_showing_up has confidence = 3.9980297e-11\n",
      "transfer_not_received_by_recipient has confidence = 2.1575982e-11\n",
      "declined_transfer has confidence = 9.160099e-12\n",
      "wrong_exchange_rate_for_cash_withdrawal has confidence = 4.0394346e-12\n",
      "top_up_reverted has confidence = 3.835578e-12\n",
      "transfer_timing has confidence = 2.1661325e-12\n",
      "balance_not_updated_after_cheque_or_cash_deposit has confidence = 6.971039e-13\n",
      "extra_charge_on_statement has confidence = 4.01189e-13\n",
      "balance_not_updated_after_bank_transfer has confidence = 3.841675e-13\n",
      "pending_cash_withdrawal has confidence = 9.829834e-14\n",
      "failed_transfer has confidence = 6.4956094e-15\n",
      "pending_card_payment has confidence = 1.3637577e-15\n",
      "pending_transfer has confidence = 1.0066043e-15\n",
      "\n",
      "ans: country_support\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = \"Which countries are represented?\"\n",
    "pred = predictions(text)\n",
    "result = get_final_output(pred, unique_intent)\n",
    "print('\\nans: {}\\n'.format(result))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Intent_classification_final.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bitf6eaa932bd364e6c99622ad728a40cf7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
