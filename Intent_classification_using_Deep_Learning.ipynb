{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Dark-Sied/Intent_Classification/blob/master/Intent_classification_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intent Classification using Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "a_WypuUXi92e",
    "outputId": "133d026e-4236-4ff6-f21d-739bfb9640db"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, GRU, LSTM, Bidirectional, Embedding, Dropout\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset link: https://raw.githubusercontent.com/PolyAI-LDN/task-specific-datasets/master/banking_data/train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Intent = \"category\"\n",
    "Sentence = \"text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LE6wywJrN2ih"
   },
   "outputs": [],
   "source": [
    "def load_dataset(filename, Sentence, Intent):\n",
    "  df = pd.read_csv(filename, names = [Sentence, Intent])\n",
    "  intent = df[Intent]\n",
    "  unique_intent = list(set(intent))\n",
    "  sentences = list(df[Sentence])\n",
    "  \n",
    "  return (df, intent, unique_intent, sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "tF0FQA7gjOCX",
    "outputId": "c609b42a-05da-49f5-8d11-bd670210f635"
   },
   "outputs": [],
   "source": [
    "df, intent, unique_intent, sentences = load_dataset(\"Dataset.csv\", \"text\", \"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text      category\n",
      "0                                               text      category\n",
      "1                     I am still waiting on my card?  card_arrival\n",
      "2  What can I do if my card still hasn't arrived ...  card_arrival\n",
      "3  I have been waiting over a week. Is the card s...  card_arrival\n",
      "4  Can I track my card while it is in the process...  card_arrival\n",
      "5  How do I know if I will get my card, or if it ...  card_arrival\n",
      "6                  When did you send me my new card?  card_arrival\n",
      "7       Do you have info about the card on delivery?  card_arrival\n",
      "8  What do I do if I still have not received my n...  card_arrival\n",
      "9       Does the package with my card have tracking?  card_arrival\n"
     ]
    }
   ],
   "source": [
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='category', ylabel='count'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import tkinter\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "sns.countplot(x=Intent, data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "O8LLUZlokg0S",
    "outputId": "c15c21dc-2ef2-43b7-b4af-e7ee9e014091"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text', 'I am still waiting on my card?', \"What can I do if my card still hasn't arrived after 2 weeks?\", 'I have been waiting over a week. Is the card still coming?', 'Can I track my card while it is in the process of delivery?']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "MhrziINPGHbW",
    "outputId": "0861af1b-4b82-4c92-b8f4-b6b57bb3e380"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/shiningflash/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/shiningflash/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OmNLu2YSXePb"
   },
   "outputs": [],
   "source": [
    "#define stemmer\n",
    "stemmer = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j-7q3iG5PKYI"
   },
   "outputs": [],
   "source": [
    "def cleaning(sentences):\n",
    "  words = []\n",
    "  for s in sentences:\n",
    "    clean = re.sub(r'[^ a-z A-Z 0-9]', \" \", s)\n",
    "    w = word_tokenize(clean)\n",
    "    words.append([i.lower() for i in w])\n",
    "    \n",
    "  return words  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "p1j2GJgDG6qj",
    "outputId": "c7232a8e-6833-4a1d-e71a-4bc7014084a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10004\n",
      "[['text'], ['i', 'am', 'still', 'waiting', 'on', 'my', 'card']]\n"
     ]
    }
   ],
   "source": [
    "cleaned_words = cleaning(sentences)\n",
    "print(len(cleaned_words))\n",
    "print(cleaned_words[:2])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Texts Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SJCQ_YhBJW7t"
   },
   "outputs": [],
   "source": [
    "def create_tokenizer(words, filters = '!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~'):\n",
    "  token = Tokenizer(filters = filters)\n",
    "  token.fit_on_texts(words)\n",
    "  return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QJhdIJC5Q3Q6"
   },
   "outputs": [],
   "source": [
    "def max_length(words):\n",
    "  return(len(max(words, key = len)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JWjxPGsZZJNX",
    "outputId": "b02c8f6b-d0df-4e90-fa3a-2ff730c88300"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size = 2343 and Maximum length = 84\n"
     ]
    }
   ],
   "source": [
    "word_tokenizer = create_tokenizer(cleaned_words)\n",
    "vocab_size = len(word_tokenizer.word_index) + 1\n",
    "max_length = max_length(cleaned_words)\n",
    "\n",
    "print(\"Vocab Size = %d and Maximum length = %d\" % (vocab_size, max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D0TXu2xsR8jq"
   },
   "outputs": [],
   "source": [
    "def encoding_doc(token, words):\n",
    "  return(token.texts_to_sequences(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dE92Hk1Va--H"
   },
   "outputs": [],
   "source": [
    "encoded_doc = encoding_doc(word_tokenizer, cleaned_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fyOzLEboc4LZ"
   },
   "outputs": [],
   "source": [
    "def padding_doc(encoded_doc, max_length):\n",
    "  return(pad_sequences(encoded_doc, maxlen = max_length, padding = \"post\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WdejoJrlc-tc"
   },
   "outputs": [],
   "source": [
    "padded_doc = padding_doc(encoded_doc, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "gDgTCS2KdI2p",
    "outputId": "ac5332cd-0a0f-4311-8db4-22df92728d90"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1481,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0],\n",
       "       [   1,   50,   64,  208,   30,    2,    6,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0],\n",
       "       [  13,    8,    1,   10,   56,    2,    6,   64,  121,   11,  275,\n",
       "         161,  453,  304,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0],\n",
       "       [   1,   27,   52,  208,  305,    4,  240,    7,    5,    6,   64,\n",
       "         454,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0],\n",
       "       [   8,    1,  361,    2,    6,  183,    9,    7,   28,    5,  216,\n",
       "          38,  362,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_doc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3eaSIDi0dNf1",
    "outputId": "4ab6b6dd-ffa4-4061-9e9d-7a01decfa837"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of padded docs =  (10004, 84)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of padded docs = \",padded_doc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X0rXzenSpgFR"
   },
   "outputs": [],
   "source": [
    "#tokenizer with filter changed\n",
    "output_tokenizer = create_tokenizer(unique_intent, filters = '!\"#$%&()*+,-/:;<=>?@[\\]^`{|}~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "yNHQtkszskxr",
    "outputId": "f5babc01-89e3-4392-e8e6-c9f257de3d07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'top_up_by_cash_or_cheque': 1,\n",
       " 'card_delivery_estimate': 2,\n",
       " 'visa_or_mastercard': 3,\n",
       " 'wrong_amount_of_cash_received': 4,\n",
       " 'beneficiary_not_allowed': 5,\n",
       " 'card_payment_wrong_exchange_rate': 6,\n",
       " 'verify_source_of_funds': 7,\n",
       " 'top_up_by_card_charge': 8,\n",
       " 'pin_blocked': 9,\n",
       " 'automatic_top_up': 10,\n",
       " 'change_pin': 11,\n",
       " 'age_limit': 12,\n",
       " 'edit_personal_details': 13,\n",
       " 'declined_cash_withdrawal': 14,\n",
       " 'card_linking': 15,\n",
       " 'order_physical_card': 16,\n",
       " 'fiat_currency_support': 17,\n",
       " 'declined_transfer': 18,\n",
       " 'topping_up_by_card': 19,\n",
       " 'top_up_limits': 20,\n",
       " 'why_verify_identity': 21,\n",
       " 'declined_card_payment': 22,\n",
       " 'cancel_transfer': 23,\n",
       " 'transfer_into_account': 24,\n",
       " 'wrong_exchange_rate_for_cash_withdrawal': 25,\n",
       " 'top_up_failed': 26,\n",
       " 'failed_transfer': 27,\n",
       " 'card_about_to_expire': 28,\n",
       " 'request_refund': 29,\n",
       " 'lost_or_stolen_phone': 30,\n",
       " 'reverted_card_payment': 31,\n",
       " 'transaction_charged_twice': 32,\n",
       " 'pending_top_up': 33,\n",
       " 'balance_not_updated_after_cheque_or_cash_deposit': 34,\n",
       " 'verify_top_up': 35,\n",
       " 'passcode_forgotten': 36,\n",
       " 'direct_debit_payment_not_recognised': 37,\n",
       " 'exchange_rate': 38,\n",
       " 'atm_support': 39,\n",
       " 'transfer_fee_charged': 40,\n",
       " 'verify_my_identity': 41,\n",
       " 'virtual_card_not_working': 42,\n",
       " 'card_not_working': 43,\n",
       " 'top_up_reverted': 44,\n",
       " 'card_acceptance': 45,\n",
       " 'get_physical_card': 46,\n",
       " 'pending_cash_withdrawal': 47,\n",
       " 'lost_or_stolen_card': 48,\n",
       " 'terminate_account': 49,\n",
       " 'exchange_charge': 50,\n",
       " 'activate_my_card': 51,\n",
       " 'top_up_by_bank_transfer_charge': 52,\n",
       " 'receiving_money': 53,\n",
       " 'compromised_card': 54,\n",
       " 'disposable_card_limits': 55,\n",
       " 'getting_spare_card': 56,\n",
       " 'get_disposable_virtual_card': 57,\n",
       " 'cash_withdrawal_not_recognised': 58,\n",
       " 'category': 59,\n",
       " 'unable_to_verify_identity': 60,\n",
       " 'supported_cards_and_currencies': 61,\n",
       " 'card_payment_not_recognised': 62,\n",
       " 'getting_virtual_card': 63,\n",
       " 'pending_card_payment': 64,\n",
       " 'pending_transfer': 65,\n",
       " 'card_arrival': 66,\n",
       " 'exchange_via_app': 67,\n",
       " 'card_swallowed': 68,\n",
       " 'balance_not_updated_after_bank_transfer': 69,\n",
       " 'apple_pay_or_google_pay': 70,\n",
       " 'country_support': 71,\n",
       " 'transfer_timing': 72,\n",
       " 'card_payment_fee_charged': 73,\n",
       " 'cash_withdrawal_charge': 74,\n",
       " 'extra_charge_on_statement': 75,\n",
       " 'contactless_not_working': 76,\n",
       " 'refund_not_showing_up': 77,\n",
       " 'transfer_not_received_by_recipient': 78}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7OOx9qdBto1-"
   },
   "outputs": [],
   "source": [
    "encoded_output = encoding_doc(output_tokenizer, intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0_5Lv5PiyG-z"
   },
   "outputs": [],
   "source": [
    "encoded_output = np.array(encoded_output).reshape(len(encoded_output), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dpM86WrVQlx5",
    "outputId": "71ff52a6-b3d0-4b5c-850d-5dc0a56c8aa9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10004, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rD3QN-RPzfet"
   },
   "outputs": [],
   "source": [
    "def one_hot(encode):\n",
    "  o = OneHotEncoder(sparse = False)\n",
    "  return(o.fit_transform(encode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z6wP_Xed7RNR"
   },
   "outputs": [],
   "source": [
    "output_one_hot = one_hot(encoded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "A6HVslLTHgOM",
    "outputId": "752962df-02d8-409b-fb8f-adb06227161d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10004, 78)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EqABUESD7xi9"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h8P4HTz6A4E-"
   },
   "outputs": [],
   "source": [
    "train_X, val_X, train_Y, val_Y = train_test_split(padded_doc, output_one_hot, shuffle = True, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "7E0uhC2OCtTx",
    "outputId": "6ce0e215-aa3f-43f1-ba5a-0b584b25a35c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_X = (8003, 84) and train_Y = (8003, 78)\n",
      "Shape of val_X = (2001, 84) and val_Y = (2001, 78)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of train_X = %s and train_Y = %s\" % (train_X.shape, train_Y.shape))\n",
    "print(\"Shape of val_X = %s and val_Y = %s\" % (val_X.shape, val_Y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Bidirectional GRU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e5BU_x74DNEb"
   },
   "outputs": [],
   "source": [
    "def create_model(vocab_size, max_length):\n",
    "  model = Sequential()\n",
    "  model.add(Embedding(vocab_size, 128, input_length = max_length, trainable = False))\n",
    "  model.add(Bidirectional(GRU(128)))\n",
    "  model.add(Dense(32, activation = \"relu\"))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Dense(78, activation = \"softmax\"))\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "f-NvE0P7MFCe",
    "outputId": "8f07056b-579e-4c15-e1af-bdfa8f681e79",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 84, 128)           299904    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 256)               198144    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 78)                2574      \n",
      "=================================================================\n",
      "Total params: 508,846\n",
      "Trainable params: 208,942\n",
      "Non-trainable params: 299,904\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(vocab_size, max_length)\n",
    "\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 6834
    },
    "colab_type": "code",
    "id": "_r-dxm2sMQ-d",
    "outputId": "3c37b4f8-fc4e-4c82-ab46-2aa1d8b47ffd"
   },
   "outputs": [],
   "source": [
    "filename = 'model.h5'\n",
    "checkpoint = ModelCheckpoint(filename,\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 4.3335 - accuracy: 0.0179\n",
      "Epoch 00001: val_loss improved from inf to 4.27058, saving model to model.h5\n",
      "251/251 [==============================] - 23s 93ms/step - loss: 4.3334 - accuracy: 0.0179 - val_loss: 4.2706 - val_accuracy: 0.0215\n",
      "Epoch 2/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 4.1094 - accuracy: 0.0352\n",
      "Epoch 00002: val_loss improved from 4.27058 to 3.81736, saving model to model.h5\n",
      "251/251 [==============================] - 26s 103ms/step - loss: 4.1094 - accuracy: 0.0352 - val_loss: 3.8174 - val_accuracy: 0.0690\n",
      "Epoch 3/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 3.7381 - accuracy: 0.0740\n",
      "Epoch 00003: val_loss improved from 3.81736 to 3.41435, saving model to model.h5\n",
      "251/251 [==============================] - 27s 106ms/step - loss: 3.7381 - accuracy: 0.0740 - val_loss: 3.4143 - val_accuracy: 0.1224\n",
      "Epoch 4/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 3.4254 - accuracy: 0.1086\n",
      "Epoch 00004: val_loss improved from 3.41435 to 3.13237, saving model to model.h5\n",
      "251/251 [==============================] - 22s 89ms/step - loss: 3.4254 - accuracy: 0.1086 - val_loss: 3.1324 - val_accuracy: 0.1759\n",
      "Epoch 5/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 3.2252 - accuracy: 0.1305\n",
      "Epoch 00005: val_loss improved from 3.13237 to 2.96009, saving model to model.h5\n",
      "251/251 [==============================] - 21s 83ms/step - loss: 3.2246 - accuracy: 0.1307 - val_loss: 2.9601 - val_accuracy: 0.1899\n",
      "Epoch 6/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 3.0463 - accuracy: 0.1566\n",
      "Epoch 00006: val_loss improved from 2.96009 to 2.76175, saving model to model.h5\n",
      "251/251 [==============================] - 24s 94ms/step - loss: 3.0459 - accuracy: 0.1567 - val_loss: 2.7618 - val_accuracy: 0.2284\n",
      "Epoch 7/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 2.9042 - accuracy: 0.1725\n",
      "Epoch 00007: val_loss improved from 2.76175 to 2.65965, saving model to model.h5\n",
      "251/251 [==============================] - 21s 83ms/step - loss: 2.9042 - accuracy: 0.1724 - val_loss: 2.6597 - val_accuracy: 0.2479\n",
      "Epoch 8/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 2.7758 - accuracy: 0.2026\n",
      "Epoch 00008: val_loss improved from 2.65965 to 2.58062, saving model to model.h5\n",
      "251/251 [==============================] - 21s 82ms/step - loss: 2.7761 - accuracy: 0.2025 - val_loss: 2.5806 - val_accuracy: 0.2614\n",
      "Epoch 9/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 2.6743 - accuracy: 0.2146\n",
      "Epoch 00009: val_loss improved from 2.58062 to 2.50623, saving model to model.h5\n",
      "251/251 [==============================] - 22s 88ms/step - loss: 2.6739 - accuracy: 0.2148 - val_loss: 2.5062 - val_accuracy: 0.2794\n",
      "Epoch 10/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 2.5910 - accuracy: 0.2379\n",
      "Epoch 00010: val_loss improved from 2.50623 to 2.35772, saving model to model.h5\n",
      "251/251 [==============================] - 20s 81ms/step - loss: 2.5912 - accuracy: 0.2378 - val_loss: 2.3577 - val_accuracy: 0.3178\n",
      "Epoch 11/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 2.5195 - accuracy: 0.2524\n",
      "Epoch 00011: val_loss improved from 2.35772 to 2.31286, saving model to model.h5\n",
      "251/251 [==============================] - 22s 88ms/step - loss: 2.5195 - accuracy: 0.2524 - val_loss: 2.3129 - val_accuracy: 0.3203\n",
      "Epoch 12/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 2.4290 - accuracy: 0.2781\n",
      "Epoch 00012: val_loss improved from 2.31286 to 2.23922, saving model to model.h5\n",
      "251/251 [==============================] - 23s 90ms/step - loss: 2.4287 - accuracy: 0.2783 - val_loss: 2.2392 - val_accuracy: 0.3393\n",
      "Epoch 13/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 2.3697 - accuracy: 0.2887\n",
      "Epoch 00013: val_loss improved from 2.23922 to 2.13489, saving model to model.h5\n",
      "251/251 [==============================] - 21s 83ms/step - loss: 2.3696 - accuracy: 0.2886 - val_loss: 2.1349 - val_accuracy: 0.3653\n",
      "Epoch 14/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 2.2854 - accuracy: 0.3026\n",
      "Epoch 00014: val_loss improved from 2.13489 to 2.11181, saving model to model.h5\n",
      "251/251 [==============================] - 20s 81ms/step - loss: 2.2850 - accuracy: 0.3026 - val_loss: 2.1118 - val_accuracy: 0.3758\n",
      "Epoch 15/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 2.2246 - accuracy: 0.3231\n",
      "Epoch 00015: val_loss improved from 2.11181 to 2.08685, saving model to model.h5\n",
      "251/251 [==============================] - 21s 83ms/step - loss: 2.2244 - accuracy: 0.3231 - val_loss: 2.0869 - val_accuracy: 0.3958\n",
      "Epoch 16/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 2.1744 - accuracy: 0.3330\n",
      "Epoch 00016: val_loss improved from 2.08685 to 1.98987, saving model to model.h5\n",
      "251/251 [==============================] - 21s 83ms/step - loss: 2.1742 - accuracy: 0.3330 - val_loss: 1.9899 - val_accuracy: 0.4173\n",
      "Epoch 17/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 2.1058 - accuracy: 0.3459\n",
      "Epoch 00017: val_loss improved from 1.98987 to 1.94376, saving model to model.h5\n",
      "251/251 [==============================] - 20s 80ms/step - loss: 2.1057 - accuracy: 0.3459 - val_loss: 1.9438 - val_accuracy: 0.4218\n",
      "Epoch 18/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 2.0692 - accuracy: 0.3589\n",
      "Epoch 00018: val_loss improved from 1.94376 to 1.88552, saving model to model.h5\n",
      "251/251 [==============================] - 20s 79ms/step - loss: 2.0688 - accuracy: 0.3590 - val_loss: 1.8855 - val_accuracy: 0.4628\n",
      "Epoch 19/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 2.0071 - accuracy: 0.3759\n",
      "Epoch 00019: val_loss improved from 1.88552 to 1.85381, saving model to model.h5\n",
      "251/251 [==============================] - 22s 88ms/step - loss: 2.0071 - accuracy: 0.3759 - val_loss: 1.8538 - val_accuracy: 0.4598\n",
      "Epoch 20/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.9553 - accuracy: 0.3950\n",
      "Epoch 00020: val_loss improved from 1.85381 to 1.84792, saving model to model.h5\n",
      "251/251 [==============================] - 22s 88ms/step - loss: 1.9551 - accuracy: 0.3950 - val_loss: 1.8479 - val_accuracy: 0.4693\n",
      "Epoch 21/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.9132 - accuracy: 0.4038\n",
      "Epoch 00021: val_loss improved from 1.84792 to 1.76239, saving model to model.h5\n",
      "251/251 [==============================] - 26s 102ms/step - loss: 1.9133 - accuracy: 0.4037 - val_loss: 1.7624 - val_accuracy: 0.4868\n",
      "Epoch 22/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.8772 - accuracy: 0.4188\n",
      "Epoch 00022: val_loss improved from 1.76239 to 1.73721, saving model to model.h5\n",
      "251/251 [==============================] - 38s 151ms/step - loss: 1.8772 - accuracy: 0.4188 - val_loss: 1.7372 - val_accuracy: 0.4988\n",
      "Epoch 23/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.8216 - accuracy: 0.4311\n",
      "Epoch 00023: val_loss did not improve from 1.73721\n",
      "251/251 [==============================] - 40s 159ms/step - loss: 1.8216 - accuracy: 0.4311 - val_loss: 1.7574 - val_accuracy: 0.4863\n",
      "Epoch 24/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.7852 - accuracy: 0.4415\n",
      "Epoch 00024: val_loss improved from 1.73721 to 1.65693, saving model to model.h5\n",
      "251/251 [==============================] - 45s 179ms/step - loss: 1.7852 - accuracy: 0.4415 - val_loss: 1.6569 - val_accuracy: 0.5282\n",
      "Epoch 25/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.7496 - accuracy: 0.4492\n",
      "Epoch 00025: val_loss improved from 1.65693 to 1.63070, saving model to model.h5\n",
      "251/251 [==============================] - 55s 218ms/step - loss: 1.7496 - accuracy: 0.4492 - val_loss: 1.6307 - val_accuracy: 0.5362\n",
      "Epoch 26/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.7145 - accuracy: 0.4561\n",
      "Epoch 00026: val_loss improved from 1.63070 to 1.62319, saving model to model.h5\n",
      "251/251 [==============================] - 54s 215ms/step - loss: 1.7145 - accuracy: 0.4561 - val_loss: 1.6232 - val_accuracy: 0.5272\n",
      "Epoch 27/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.6668 - accuracy: 0.4687\n",
      "Epoch 00027: val_loss improved from 1.62319 to 1.57346, saving model to model.h5\n",
      "251/251 [==============================] - 51s 204ms/step - loss: 1.6668 - accuracy: 0.4687 - val_loss: 1.5735 - val_accuracy: 0.5572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.6319 - accuracy: 0.4842\n",
      "Epoch 00028: val_loss did not improve from 1.57346\n",
      "251/251 [==============================] - 44s 174ms/step - loss: 1.6319 - accuracy: 0.4842 - val_loss: 1.5962 - val_accuracy: 0.5632\n",
      "Epoch 29/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.6075 - accuracy: 0.4882\n",
      "Epoch 00029: val_loss did not improve from 1.57346\n",
      "251/251 [==============================] - 44s 175ms/step - loss: 1.6075 - accuracy: 0.4882 - val_loss: 1.5836 - val_accuracy: 0.5632\n",
      "Epoch 30/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.5591 - accuracy: 0.4993\n",
      "Epoch 00030: val_loss improved from 1.57346 to 1.52777, saving model to model.h5\n",
      "251/251 [==============================] - 44s 174ms/step - loss: 1.5591 - accuracy: 0.4993 - val_loss: 1.5278 - val_accuracy: 0.5782\n",
      "Epoch 31/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.5530 - accuracy: 0.5071\n",
      "Epoch 00031: val_loss improved from 1.52777 to 1.52052, saving model to model.h5\n",
      "251/251 [==============================] - 49s 194ms/step - loss: 1.5530 - accuracy: 0.5071 - val_loss: 1.5205 - val_accuracy: 0.5817\n",
      "Epoch 32/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.4849 - accuracy: 0.5273\n",
      "Epoch 00032: val_loss did not improve from 1.52052\n",
      "251/251 [==============================] - 46s 184ms/step - loss: 1.4849 - accuracy: 0.5273 - val_loss: 1.5332 - val_accuracy: 0.5842\n",
      "Epoch 33/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.4670 - accuracy: 0.5326\n",
      "Epoch 00033: val_loss did not improve from 1.52052\n",
      "251/251 [==============================] - 54s 217ms/step - loss: 1.4670 - accuracy: 0.5326 - val_loss: 1.5420 - val_accuracy: 0.5962\n",
      "Epoch 34/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.4345 - accuracy: 0.5390\n",
      "Epoch 00034: val_loss improved from 1.52052 to 1.48726, saving model to model.h5\n",
      "251/251 [==============================] - 50s 199ms/step - loss: 1.4345 - accuracy: 0.5390 - val_loss: 1.4873 - val_accuracy: 0.5867\n",
      "Epoch 35/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.4037 - accuracy: 0.5477\n",
      "Epoch 00035: val_loss did not improve from 1.48726\n",
      "251/251 [==============================] - 52s 207ms/step - loss: 1.4037 - accuracy: 0.5477 - val_loss: 1.5423 - val_accuracy: 0.5947\n",
      "Epoch 36/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.4160 - accuracy: 0.5444\n",
      "Epoch 00036: val_loss did not improve from 1.48726\n",
      "251/251 [==============================] - 30s 120ms/step - loss: 1.4160 - accuracy: 0.5444 - val_loss: 1.5370 - val_accuracy: 0.5862\n",
      "Epoch 37/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.3532 - accuracy: 0.5593\n",
      "Epoch 00037: val_loss improved from 1.48726 to 1.48493, saving model to model.h5\n",
      "251/251 [==============================] - 29s 115ms/step - loss: 1.3532 - accuracy: 0.5593 - val_loss: 1.4849 - val_accuracy: 0.6107\n",
      "Epoch 38/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.3427 - accuracy: 0.5608\n",
      "Epoch 00038: val_loss did not improve from 1.48493\n",
      "251/251 [==============================] - 27s 109ms/step - loss: 1.3427 - accuracy: 0.5608 - val_loss: 1.4905 - val_accuracy: 0.6227\n",
      "Epoch 39/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.2975 - accuracy: 0.5857\n",
      "Epoch 00039: val_loss improved from 1.48493 to 1.44457, saving model to model.h5\n",
      "251/251 [==============================] - 28s 111ms/step - loss: 1.2981 - accuracy: 0.5857 - val_loss: 1.4446 - val_accuracy: 0.6237\n",
      "Epoch 40/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.2937 - accuracy: 0.5773\n",
      "Epoch 00040: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 26s 105ms/step - loss: 1.2937 - accuracy: 0.5773 - val_loss: 1.4843 - val_accuracy: 0.6272\n",
      "Epoch 41/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.2403 - accuracy: 0.5977\n",
      "Epoch 00041: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 25s 100ms/step - loss: 1.2403 - accuracy: 0.5977 - val_loss: 1.5572 - val_accuracy: 0.6232\n",
      "Epoch 42/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.2261 - accuracy: 0.5960\n",
      "Epoch 00042: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 23s 93ms/step - loss: 1.2261 - accuracy: 0.5960 - val_loss: 1.5840 - val_accuracy: 0.6137\n",
      "Epoch 43/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.2664 - accuracy: 0.5891\n",
      "Epoch 00043: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 23s 92ms/step - loss: 1.2664 - accuracy: 0.5890 - val_loss: 1.5171 - val_accuracy: 0.6347\n",
      "Epoch 44/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.1855 - accuracy: 0.6094\n",
      "Epoch 00044: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 28s 110ms/step - loss: 1.1855 - accuracy: 0.6094 - val_loss: 1.4855 - val_accuracy: 0.6367\n",
      "Epoch 45/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.1386 - accuracy: 0.6145\n",
      "Epoch 00045: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 27s 109ms/step - loss: 1.1386 - accuracy: 0.6145 - val_loss: 1.5674 - val_accuracy: 0.6102\n",
      "Epoch 46/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.1428 - accuracy: 0.6208\n",
      "Epoch 00046: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 27s 107ms/step - loss: 1.1428 - accuracy: 0.6208 - val_loss: 1.4835 - val_accuracy: 0.6347\n",
      "Epoch 47/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.1170 - accuracy: 0.6324\n",
      "Epoch 00047: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 29s 115ms/step - loss: 1.1170 - accuracy: 0.6324 - val_loss: 1.5337 - val_accuracy: 0.6472\n",
      "Epoch 48/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.0891 - accuracy: 0.6371\n",
      "Epoch 00048: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 28s 113ms/step - loss: 1.0891 - accuracy: 0.6371 - val_loss: 1.4967 - val_accuracy: 0.6497\n",
      "Epoch 49/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.0769 - accuracy: 0.6435\n",
      "Epoch 00049: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 27s 109ms/step - loss: 1.0769 - accuracy: 0.6435 - val_loss: 1.5394 - val_accuracy: 0.6402\n",
      "Epoch 50/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.0580 - accuracy: 0.6440\n",
      "Epoch 00050: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 28s 113ms/step - loss: 1.0580 - accuracy: 0.6440 - val_loss: 1.5288 - val_accuracy: 0.6467\n",
      "Epoch 51/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.0260 - accuracy: 0.6565\n",
      "Epoch 00051: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 29s 116ms/step - loss: 1.0257 - accuracy: 0.6566 - val_loss: 1.5142 - val_accuracy: 0.6532\n",
      "Epoch 52/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.0224 - accuracy: 0.6613\n",
      "Epoch 00052: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 38s 150ms/step - loss: 1.0224 - accuracy: 0.6613 - val_loss: 1.4909 - val_accuracy: 0.6592\n",
      "Epoch 53/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.0085 - accuracy: 0.6620\n",
      "Epoch 00053: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 37s 149ms/step - loss: 1.0085 - accuracy: 0.6620 - val_loss: 1.5250 - val_accuracy: 0.6522\n",
      "Epoch 54/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.9991 - accuracy: 0.6664\n",
      "Epoch 00054: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 39s 157ms/step - loss: 0.9991 - accuracy: 0.6664 - val_loss: 1.5270 - val_accuracy: 0.6552\n",
      "Epoch 55/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.9793 - accuracy: 0.6676\n",
      "Epoch 00055: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 35s 138ms/step - loss: 0.9793 - accuracy: 0.6676 - val_loss: 1.5554 - val_accuracy: 0.6707\n",
      "Epoch 56/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.9268 - accuracy: 0.6797\n",
      "Epoch 00056: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 29s 114ms/step - loss: 0.9268 - accuracy: 0.6797 - val_loss: 1.5295 - val_accuracy: 0.6642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.9439 - accuracy: 0.6802\n",
      "Epoch 00057: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 29s 116ms/step - loss: 0.9439 - accuracy: 0.6802 - val_loss: 1.5952 - val_accuracy: 0.6642\n",
      "Epoch 58/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.9087 - accuracy: 0.6946\n",
      "Epoch 00058: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 29s 117ms/step - loss: 0.9087 - accuracy: 0.6946 - val_loss: 1.5913 - val_accuracy: 0.6622\n",
      "Epoch 59/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.9004 - accuracy: 0.6955\n",
      "Epoch 00059: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 29s 115ms/step - loss: 0.9004 - accuracy: 0.6955 - val_loss: 1.6798 - val_accuracy: 0.6532\n",
      "Epoch 60/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.8781 - accuracy: 0.6970\n",
      "Epoch 00060: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 22s 88ms/step - loss: 0.8780 - accuracy: 0.6971 - val_loss: 1.6234 - val_accuracy: 0.6727\n",
      "Epoch 61/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.8709 - accuracy: 0.7005\n",
      "Epoch 00061: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 22s 87ms/step - loss: 0.8711 - accuracy: 0.7005 - val_loss: 1.6448 - val_accuracy: 0.6727\n",
      "Epoch 62/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.8663 - accuracy: 0.7039\n",
      "Epoch 00062: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 22s 87ms/step - loss: 0.8664 - accuracy: 0.7039 - val_loss: 1.7071 - val_accuracy: 0.6687\n",
      "Epoch 63/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.8500 - accuracy: 0.7113\n",
      "Epoch 00063: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 22s 87ms/step - loss: 0.8500 - accuracy: 0.7112 - val_loss: 1.6326 - val_accuracy: 0.6732\n",
      "Epoch 64/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.8341 - accuracy: 0.7102\n",
      "Epoch 00064: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 22s 87ms/step - loss: 0.8341 - accuracy: 0.7102 - val_loss: 1.6507 - val_accuracy: 0.6782\n",
      "Epoch 65/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.8156 - accuracy: 0.7172\n",
      "Epoch 00065: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 22s 87ms/step - loss: 0.8154 - accuracy: 0.7174 - val_loss: 1.7312 - val_accuracy: 0.6652\n",
      "Epoch 66/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.8050 - accuracy: 0.7207\n",
      "Epoch 00066: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 22s 88ms/step - loss: 0.8047 - accuracy: 0.7209 - val_loss: 1.7547 - val_accuracy: 0.6607\n",
      "Epoch 67/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.7792 - accuracy: 0.7297\n",
      "Epoch 00067: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 22s 88ms/step - loss: 0.7792 - accuracy: 0.7299 - val_loss: 1.7610 - val_accuracy: 0.6757\n",
      "Epoch 68/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.7789 - accuracy: 0.7333\n",
      "Epoch 00068: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 22s 87ms/step - loss: 0.7786 - accuracy: 0.7333 - val_loss: 1.6850 - val_accuracy: 0.6717\n",
      "Epoch 69/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.7749 - accuracy: 0.7364\n",
      "Epoch 00069: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 38s 151ms/step - loss: 0.7748 - accuracy: 0.7363 - val_loss: 1.7332 - val_accuracy: 0.6737\n",
      "Epoch 70/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.7432 - accuracy: 0.7372\n",
      "Epoch 00070: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 25s 98ms/step - loss: 0.7429 - accuracy: 0.7373 - val_loss: 1.8610 - val_accuracy: 0.6822\n",
      "Epoch 71/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.7326 - accuracy: 0.7445\n",
      "Epoch 00071: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 22s 88ms/step - loss: 0.7325 - accuracy: 0.7446 - val_loss: 1.7883 - val_accuracy: 0.6872\n",
      "Epoch 72/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.7453 - accuracy: 0.7404\n",
      "Epoch 00072: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 22s 87ms/step - loss: 0.7458 - accuracy: 0.7402 - val_loss: 1.8509 - val_accuracy: 0.6832\n",
      "Epoch 73/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.7157 - accuracy: 0.7517\n",
      "Epoch 00073: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 22s 86ms/step - loss: 0.7163 - accuracy: 0.7516 - val_loss: 1.8285 - val_accuracy: 0.6847\n",
      "Epoch 74/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.7224 - accuracy: 0.7500\n",
      "Epoch 00074: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 22s 87ms/step - loss: 0.7222 - accuracy: 0.7501 - val_loss: 1.9006 - val_accuracy: 0.6782\n",
      "Epoch 75/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.7251 - accuracy: 0.7450\n",
      "Epoch 00075: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 22s 87ms/step - loss: 0.7251 - accuracy: 0.7450 - val_loss: 1.8626 - val_accuracy: 0.6692\n",
      "Epoch 76/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.6800 - accuracy: 0.7628\n",
      "Epoch 00076: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 22s 87ms/step - loss: 0.6800 - accuracy: 0.7627 - val_loss: 1.9267 - val_accuracy: 0.6932\n",
      "Epoch 77/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.6852 - accuracy: 0.7619\n",
      "Epoch 00077: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 22s 87ms/step - loss: 0.6853 - accuracy: 0.7617 - val_loss: 1.8616 - val_accuracy: 0.6872\n",
      "Epoch 78/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.6749 - accuracy: 0.7615\n",
      "Epoch 00078: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 22s 87ms/step - loss: 0.6747 - accuracy: 0.7616 - val_loss: 2.0164 - val_accuracy: 0.6792\n",
      "Epoch 79/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.6499 - accuracy: 0.7745\n",
      "Epoch 00079: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 22s 88ms/step - loss: 0.6500 - accuracy: 0.7745 - val_loss: 1.8782 - val_accuracy: 0.6927\n",
      "Epoch 80/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.6679 - accuracy: 0.7676\n",
      "Epoch 00080: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 23s 90ms/step - loss: 0.6677 - accuracy: 0.7677 - val_loss: 1.9416 - val_accuracy: 0.6782\n",
      "Epoch 81/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.6359 - accuracy: 0.7716\n",
      "Epoch 00081: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 22s 87ms/step - loss: 0.6357 - accuracy: 0.7717 - val_loss: 1.9453 - val_accuracy: 0.6962\n",
      "Epoch 82/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.6212 - accuracy: 0.7830\n",
      "Epoch 00082: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 22s 87ms/step - loss: 0.6214 - accuracy: 0.7830 - val_loss: 1.8328 - val_accuracy: 0.6907\n",
      "Epoch 83/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.6386 - accuracy: 0.7735\n",
      "Epoch 00083: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 22s 86ms/step - loss: 0.6386 - accuracy: 0.7735 - val_loss: 2.0188 - val_accuracy: 0.6902\n",
      "Epoch 84/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.6547 - accuracy: 0.7704\n",
      "Epoch 00084: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 22s 86ms/step - loss: 0.6545 - accuracy: 0.7705 - val_loss: 2.0437 - val_accuracy: 0.6917\n",
      "Epoch 85/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.6098 - accuracy: 0.7878\n",
      "Epoch 00085: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 22s 88ms/step - loss: 0.6096 - accuracy: 0.7878 - val_loss: 2.0177 - val_accuracy: 0.6927\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/251 [============================>.] - ETA: 0s - loss: 0.6293 - accuracy: 0.7812\n",
      "Epoch 00086: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 23s 90ms/step - loss: 0.6293 - accuracy: 0.7813 - val_loss: 2.0607 - val_accuracy: 0.7016\n",
      "Epoch 87/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.6056 - accuracy: 0.7820\n",
      "Epoch 00087: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 22s 87ms/step - loss: 0.6054 - accuracy: 0.7821 - val_loss: 1.9644 - val_accuracy: 0.6902\n",
      "Epoch 88/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.6456 - accuracy: 0.7799\n",
      "Epoch 00088: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 22s 87ms/step - loss: 0.6462 - accuracy: 0.7798 - val_loss: 2.0080 - val_accuracy: 0.6852\n",
      "Epoch 89/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.6215 - accuracy: 0.7843\n",
      "Epoch 00089: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 22s 87ms/step - loss: 0.6213 - accuracy: 0.7843 - val_loss: 2.0475 - val_accuracy: 0.6947\n",
      "Epoch 90/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.5761 - accuracy: 0.7954\n",
      "Epoch 00090: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 22s 86ms/step - loss: 0.5762 - accuracy: 0.7952 - val_loss: 2.1777 - val_accuracy: 0.6877\n",
      "Epoch 91/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.5653 - accuracy: 0.7959\n",
      "Epoch 00091: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 27s 107ms/step - loss: 0.5654 - accuracy: 0.7958 - val_loss: 2.1215 - val_accuracy: 0.6937\n",
      "Epoch 92/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.5704 - accuracy: 0.7987\n",
      "Epoch 00092: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 30s 121ms/step - loss: 0.5705 - accuracy: 0.7987 - val_loss: 2.1993 - val_accuracy: 0.6777\n",
      "Epoch 93/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.5979 - accuracy: 0.7901\n",
      "Epoch 00093: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 30s 118ms/step - loss: 0.5984 - accuracy: 0.7901 - val_loss: 2.2655 - val_accuracy: 0.6817\n",
      "Epoch 94/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.5628 - accuracy: 0.7987\n",
      "Epoch 00094: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 22s 87ms/step - loss: 0.5627 - accuracy: 0.7988 - val_loss: 2.1356 - val_accuracy: 0.6947\n",
      "Epoch 95/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.5243 - accuracy: 0.8164\n",
      "Epoch 00095: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 22s 88ms/step - loss: 0.5244 - accuracy: 0.8163 - val_loss: 2.1908 - val_accuracy: 0.6962\n",
      "Epoch 96/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.5378 - accuracy: 0.8055\n",
      "Epoch 00096: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 22s 87ms/step - loss: 0.5377 - accuracy: 0.8056 - val_loss: 2.3204 - val_accuracy: 0.6867\n",
      "Epoch 97/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.5264 - accuracy: 0.8106\n",
      "Epoch 00097: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 22s 87ms/step - loss: 0.5262 - accuracy: 0.8107 - val_loss: 2.3225 - val_accuracy: 0.6867\n",
      "Epoch 98/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.5299 - accuracy: 0.8131\n",
      "Epoch 00098: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 22s 87ms/step - loss: 0.5298 - accuracy: 0.8132 - val_loss: 2.3495 - val_accuracy: 0.6972\n",
      "Epoch 99/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.6215 - accuracy: 0.7827\n",
      "Epoch 00099: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 22s 87ms/step - loss: 0.6215 - accuracy: 0.7827 - val_loss: 2.2520 - val_accuracy: 0.6887\n",
      "Epoch 100/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.5402 - accuracy: 0.8124\n",
      "Epoch 00100: val_loss did not improve from 1.44457\n",
      "251/251 [==============================] - 22s 87ms/step - loss: 0.5402 - accuracy: 0.8123 - val_loss: 2.3806 - val_accuracy: 0.6922\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(train_X, train_Y,\n",
    "                 epochs = 100,\n",
    "                 batch_size = 32,\n",
    "                 validation_data = (val_X, val_Y),\n",
    "                 callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Bidirectional LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 84, 128)           299904    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 256)               198144    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 78)                2574      \n",
      "=================================================================\n",
      "Total params: 508,846\n",
      "Trainable params: 208,942\n",
      "Non-trainable params: 299,904\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model(vocab_size, max_length):\n",
    "  model = Sequential()\n",
    "  model.add(Embedding(vocab_size, 128, input_length = max_length, trainable = False))\n",
    "  model.add(Bidirectional(GRU(128)))\n",
    "  model.add(Dense(32, activation = \"relu\"))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Dense(78, activation = \"softmax\"))\n",
    "  \n",
    "  return model\n",
    "\n",
    "model_lstm = create_model(vocab_size, max_length)\n",
    "\n",
    "model_lstm.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 4.3337 - accuracy: 0.0188\n",
      "Epoch 00001: val_loss improved from inf to 4.27265, saving model to model.h5\n",
      "251/251 [==============================] - 22s 86ms/step - loss: 4.3337 - accuracy: 0.0187 - val_loss: 4.2727 - val_accuracy: 0.0240\n",
      "Epoch 2/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 4.1330 - accuracy: 0.0307\n",
      "Epoch 00002: val_loss improved from 4.27265 to 3.94408, saving model to model.h5\n",
      "251/251 [==============================] - 30s 118ms/step - loss: 4.1330 - accuracy: 0.0307 - val_loss: 3.9441 - val_accuracy: 0.0460\n",
      "Epoch 3/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 3.8935 - accuracy: 0.0562\n",
      "Epoch 00003: val_loss improved from 3.94408 to 3.64672, saving model to model.h5\n",
      "251/251 [==============================] - 30s 120ms/step - loss: 3.8934 - accuracy: 0.0564 - val_loss: 3.6467 - val_accuracy: 0.0820\n",
      "Epoch 4/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 3.6066 - accuracy: 0.0824\n",
      "Epoch 00004: val_loss improved from 3.64672 to 3.23732, saving model to model.h5\n",
      "251/251 [==============================] - 24s 97ms/step - loss: 3.6066 - accuracy: 0.0823 - val_loss: 3.2373 - val_accuracy: 0.1374\n",
      "Epoch 5/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 3.3376 - accuracy: 0.1140\n",
      "Epoch 00005: val_loss improved from 3.23732 to 3.05696, saving model to model.h5\n",
      "251/251 [==============================] - 24s 95ms/step - loss: 3.3376 - accuracy: 0.1140 - val_loss: 3.0570 - val_accuracy: 0.1744\n",
      "Epoch 6/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 3.1163 - accuracy: 0.1398\n",
      "Epoch 00006: val_loss improved from 3.05696 to 2.79989, saving model to model.h5\n",
      "251/251 [==============================] - 28s 112ms/step - loss: 3.1163 - accuracy: 0.1398 - val_loss: 2.7999 - val_accuracy: 0.2254\n",
      "Epoch 7/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 2.9559 - accuracy: 0.1663\n",
      "Epoch 00007: val_loss improved from 2.79989 to 2.64152, saving model to model.h5\n",
      "251/251 [==============================] - 20s 78ms/step - loss: 2.9562 - accuracy: 0.1662 - val_loss: 2.6415 - val_accuracy: 0.2534\n",
      "Epoch 8/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 2.7911 - accuracy: 0.2014\n",
      "Epoch 00008: val_loss improved from 2.64152 to 2.48571, saving model to model.h5\n",
      "251/251 [==============================] - 22s 88ms/step - loss: 2.7906 - accuracy: 0.2014 - val_loss: 2.4857 - val_accuracy: 0.2719\n",
      "Epoch 9/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 2.6792 - accuracy: 0.2166\n",
      "Epoch 00009: val_loss improved from 2.48571 to 2.36167, saving model to model.h5\n",
      "251/251 [==============================] - 20s 79ms/step - loss: 2.6792 - accuracy: 0.2167 - val_loss: 2.3617 - val_accuracy: 0.3063\n",
      "Epoch 10/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 2.5443 - accuracy: 0.2549\n",
      "Epoch 00010: val_loss improved from 2.36167 to 2.26401, saving model to model.h5\n",
      "251/251 [==============================] - 19s 77ms/step - loss: 2.5442 - accuracy: 0.2548 - val_loss: 2.2640 - val_accuracy: 0.3293\n",
      "Epoch 11/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 2.4382 - accuracy: 0.2663\n",
      "Epoch 00011: val_loss improved from 2.26401 to 2.18261, saving model to model.h5\n",
      "251/251 [==============================] - 19s 77ms/step - loss: 2.4387 - accuracy: 0.2662 - val_loss: 2.1826 - val_accuracy: 0.3633\n",
      "Epoch 12/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 2.3773 - accuracy: 0.2824\n",
      "Epoch 00012: val_loss improved from 2.18261 to 2.13561, saving model to model.h5\n",
      "251/251 [==============================] - 21s 84ms/step - loss: 2.3774 - accuracy: 0.2824 - val_loss: 2.1356 - val_accuracy: 0.3538\n",
      "Epoch 13/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 2.2824 - accuracy: 0.3079\n",
      "Epoch 00013: val_loss improved from 2.13561 to 2.03981, saving model to model.h5\n",
      "251/251 [==============================] - 23s 92ms/step - loss: 2.2826 - accuracy: 0.3079 - val_loss: 2.0398 - val_accuracy: 0.3913\n",
      "Epoch 14/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 2.2253 - accuracy: 0.3203\n",
      "Epoch 00014: val_loss improved from 2.03981 to 1.96118, saving model to model.h5\n",
      "251/251 [==============================] - 19s 75ms/step - loss: 2.2252 - accuracy: 0.3203 - val_loss: 1.9612 - val_accuracy: 0.4208\n",
      "Epoch 15/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 2.1420 - accuracy: 0.3351\n",
      "Epoch 00015: val_loss improved from 1.96118 to 1.92070, saving model to model.h5\n",
      "251/251 [==============================] - 19s 76ms/step - loss: 2.1416 - accuracy: 0.3354 - val_loss: 1.9207 - val_accuracy: 0.4133\n",
      "Epoch 16/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 2.0963 - accuracy: 0.3614\n",
      "Epoch 00016: val_loss improved from 1.92070 to 1.90697, saving model to model.h5\n",
      "251/251 [==============================] - 20s 80ms/step - loss: 2.0961 - accuracy: 0.3614 - val_loss: 1.9070 - val_accuracy: 0.4288\n",
      "Epoch 17/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 2.0274 - accuracy: 0.3668\n",
      "Epoch 00017: val_loss improved from 1.90697 to 1.83711, saving model to model.h5\n",
      "251/251 [==============================] - 21s 85ms/step - loss: 2.0275 - accuracy: 0.3667 - val_loss: 1.8371 - val_accuracy: 0.4608\n",
      "Epoch 18/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.9945 - accuracy: 0.3812\n",
      "Epoch 00018: val_loss improved from 1.83711 to 1.78613, saving model to model.h5\n",
      "251/251 [==============================] - 19s 74ms/step - loss: 1.9944 - accuracy: 0.3812 - val_loss: 1.7861 - val_accuracy: 0.4773\n",
      "Epoch 19/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.9376 - accuracy: 0.3919\n",
      "Epoch 00019: val_loss improved from 1.78613 to 1.75560, saving model to model.h5\n",
      "251/251 [==============================] - 19s 76ms/step - loss: 1.9374 - accuracy: 0.3920 - val_loss: 1.7556 - val_accuracy: 0.4883\n",
      "Epoch 20/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.9146 - accuracy: 0.3960\n",
      "Epoch 00020: val_loss did not improve from 1.75560\n",
      "251/251 [==============================] - 19s 74ms/step - loss: 1.9149 - accuracy: 0.3959 - val_loss: 1.7710 - val_accuracy: 0.4743\n",
      "Epoch 21/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.8692 - accuracy: 0.4126\n",
      "Epoch 00021: val_loss improved from 1.75560 to 1.68554, saving model to model.h5\n",
      "251/251 [==============================] - 19s 75ms/step - loss: 1.8692 - accuracy: 0.4125 - val_loss: 1.6855 - val_accuracy: 0.4963\n",
      "Epoch 22/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.8215 - accuracy: 0.4251\n",
      "Epoch 00022: val_loss improved from 1.68554 to 1.67111, saving model to model.h5\n",
      "251/251 [==============================] - 21s 85ms/step - loss: 1.8216 - accuracy: 0.4250 - val_loss: 1.6711 - val_accuracy: 0.4828\n",
      "Epoch 23/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.7742 - accuracy: 0.4336\n",
      "Epoch 00023: val_loss improved from 1.67111 to 1.62294, saving model to model.h5\n",
      "251/251 [==============================] - 23s 92ms/step - loss: 1.7746 - accuracy: 0.4335 - val_loss: 1.6229 - val_accuracy: 0.5212\n",
      "Epoch 24/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.7232 - accuracy: 0.4431\n",
      "Epoch 00024: val_loss improved from 1.62294 to 1.61406, saving model to model.h5\n",
      "251/251 [==============================] - 23s 92ms/step - loss: 1.7232 - accuracy: 0.4432 - val_loss: 1.6141 - val_accuracy: 0.5337\n",
      "Epoch 25/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.6907 - accuracy: 0.4577\n",
      "Epoch 00025: val_loss improved from 1.61406 to 1.56826, saving model to model.h5\n",
      "251/251 [==============================] - 27s 106ms/step - loss: 1.6904 - accuracy: 0.4578 - val_loss: 1.5683 - val_accuracy: 0.5397\n",
      "Epoch 26/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.6465 - accuracy: 0.4723\n",
      "Epoch 00026: val_loss did not improve from 1.56826\n",
      "251/251 [==============================] - 29s 115ms/step - loss: 1.6465 - accuracy: 0.4723 - val_loss: 1.5739 - val_accuracy: 0.5442\n",
      "Epoch 27/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.6174 - accuracy: 0.4819\n",
      "Epoch 00027: val_loss improved from 1.56826 to 1.53518, saving model to model.h5\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 1.6174 - accuracy: 0.4819 - val_loss: 1.5352 - val_accuracy: 0.5517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.5961 - accuracy: 0.4863\n",
      "Epoch 00028: val_loss improved from 1.53518 to 1.52079, saving model to model.h5\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 1.5961 - accuracy: 0.4863 - val_loss: 1.5208 - val_accuracy: 0.5637\n",
      "Epoch 29/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.5584 - accuracy: 0.4946\n",
      "Epoch 00029: val_loss improved from 1.52079 to 1.51989, saving model to model.h5\n",
      "251/251 [==============================] - 21s 84ms/step - loss: 1.5580 - accuracy: 0.4947 - val_loss: 1.5199 - val_accuracy: 0.5597\n",
      "Epoch 30/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.5395 - accuracy: 0.5059\n",
      "Epoch 00030: val_loss improved from 1.51989 to 1.47681, saving model to model.h5\n",
      "251/251 [==============================] - 22s 88ms/step - loss: 1.5393 - accuracy: 0.5059 - val_loss: 1.4768 - val_accuracy: 0.5772\n",
      "Epoch 31/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.4978 - accuracy: 0.5113\n",
      "Epoch 00031: val_loss did not improve from 1.47681\n",
      "251/251 [==============================] - 20s 81ms/step - loss: 1.4978 - accuracy: 0.5112 - val_loss: 1.4939 - val_accuracy: 0.5682\n",
      "Epoch 32/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.4708 - accuracy: 0.5206\n",
      "Epoch 00032: val_loss did not improve from 1.47681\n",
      "251/251 [==============================] - 21s 82ms/step - loss: 1.4711 - accuracy: 0.5206 - val_loss: 1.4886 - val_accuracy: 0.5887\n",
      "Epoch 33/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.4506 - accuracy: 0.5157\n",
      "Epoch 00033: val_loss improved from 1.47681 to 1.43358, saving model to model.h5\n",
      "251/251 [==============================] - 24s 95ms/step - loss: 1.4506 - accuracy: 0.5157 - val_loss: 1.4336 - val_accuracy: 0.5892\n",
      "Epoch 34/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.4201 - accuracy: 0.5386\n",
      "Epoch 00034: val_loss did not improve from 1.43358\n",
      "251/251 [==============================] - 28s 114ms/step - loss: 1.4208 - accuracy: 0.5384 - val_loss: 1.4936 - val_accuracy: 0.5722\n",
      "Epoch 35/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.3793 - accuracy: 0.5415\n",
      "Epoch 00035: val_loss improved from 1.43358 to 1.43167, saving model to model.h5\n",
      "251/251 [==============================] - 25s 99ms/step - loss: 1.3793 - accuracy: 0.5415 - val_loss: 1.4317 - val_accuracy: 0.6012\n",
      "Epoch 36/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.3316 - accuracy: 0.5584\n",
      "Epoch 00036: val_loss did not improve from 1.43167\n",
      "251/251 [==============================] - 22s 86ms/step - loss: 1.3313 - accuracy: 0.5584 - val_loss: 1.4490 - val_accuracy: 0.6097\n",
      "Epoch 37/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 1.3410 - accuracy: 0.5569\n",
      "Epoch 00037: val_loss improved from 1.43167 to 1.40131, saving model to model.h5\n",
      "251/251 [==============================] - 35s 139ms/step - loss: 1.3410 - accuracy: 0.5569 - val_loss: 1.4013 - val_accuracy: 0.6092\n",
      "Epoch 38/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.2971 - accuracy: 0.5719\n",
      "Epoch 00038: val_loss did not improve from 1.40131\n",
      "251/251 [==============================] - 23s 91ms/step - loss: 1.2971 - accuracy: 0.5718 - val_loss: 1.4842 - val_accuracy: 0.5947\n",
      "Epoch 39/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.2807 - accuracy: 0.5761\n",
      "Epoch 00039: val_loss did not improve from 1.40131\n",
      "251/251 [==============================] - 20s 79ms/step - loss: 1.2806 - accuracy: 0.5760 - val_loss: 1.4172 - val_accuracy: 0.6107\n",
      "Epoch 40/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.2446 - accuracy: 0.5811\n",
      "Epoch 00040: val_loss improved from 1.40131 to 1.39536, saving model to model.h5\n",
      "251/251 [==============================] - 21s 82ms/step - loss: 1.2442 - accuracy: 0.5813 - val_loss: 1.3954 - val_accuracy: 0.6127\n",
      "Epoch 41/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.2128 - accuracy: 0.5901\n",
      "Epoch 00041: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 19s 77ms/step - loss: 1.2125 - accuracy: 0.5903 - val_loss: 1.4070 - val_accuracy: 0.6242\n",
      "Epoch 42/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.2083 - accuracy: 0.5921\n",
      "Epoch 00042: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 20s 79ms/step - loss: 1.2086 - accuracy: 0.5920 - val_loss: 1.3974 - val_accuracy: 0.6302\n",
      "Epoch 43/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.2033 - accuracy: 0.5974\n",
      "Epoch 00043: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 19s 76ms/step - loss: 1.2033 - accuracy: 0.5973 - val_loss: 1.4173 - val_accuracy: 0.6252\n",
      "Epoch 44/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.1614 - accuracy: 0.6043\n",
      "Epoch 00044: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 21s 82ms/step - loss: 1.1611 - accuracy: 0.6044 - val_loss: 1.4085 - val_accuracy: 0.6262\n",
      "Epoch 45/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.1169 - accuracy: 0.6217\n",
      "Epoch 00045: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 22s 87ms/step - loss: 1.1174 - accuracy: 0.6215 - val_loss: 1.4679 - val_accuracy: 0.6272\n",
      "Epoch 46/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.1135 - accuracy: 0.6220\n",
      "Epoch 00046: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 20s 79ms/step - loss: 1.1132 - accuracy: 0.6221 - val_loss: 1.4306 - val_accuracy: 0.6287\n",
      "Epoch 47/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.1191 - accuracy: 0.6244\n",
      "Epoch 00047: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 20s 80ms/step - loss: 1.1188 - accuracy: 0.6245 - val_loss: 1.4338 - val_accuracy: 0.6342\n",
      "Epoch 48/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.0953 - accuracy: 0.6346\n",
      "Epoch 00048: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 20s 81ms/step - loss: 1.0954 - accuracy: 0.6345 - val_loss: 1.4591 - val_accuracy: 0.6267\n",
      "Epoch 49/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.0603 - accuracy: 0.6415\n",
      "Epoch 00049: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 19s 76ms/step - loss: 1.0600 - accuracy: 0.6415 - val_loss: 1.4817 - val_accuracy: 0.6407\n",
      "Epoch 50/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.0684 - accuracy: 0.6388\n",
      "Epoch 00050: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 22s 89ms/step - loss: 1.0688 - accuracy: 0.6385 - val_loss: 1.4735 - val_accuracy: 0.6302\n",
      "Epoch 51/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.0324 - accuracy: 0.6457\n",
      "Epoch 00051: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 20s 81ms/step - loss: 1.0323 - accuracy: 0.6459 - val_loss: 1.5178 - val_accuracy: 0.6417\n",
      "Epoch 52/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.0012 - accuracy: 0.6544\n",
      "Epoch 00052: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 19s 77ms/step - loss: 1.0014 - accuracy: 0.6543 - val_loss: 1.5634 - val_accuracy: 0.6247\n",
      "Epoch 53/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.0026 - accuracy: 0.6589\n",
      "Epoch 00053: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 20s 79ms/step - loss: 1.0027 - accuracy: 0.6589 - val_loss: 1.4810 - val_accuracy: 0.6427\n",
      "Epoch 54/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.9872 - accuracy: 0.6624\n",
      "Epoch 00054: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 20s 79ms/step - loss: 0.9870 - accuracy: 0.6625 - val_loss: 1.4839 - val_accuracy: 0.6542\n",
      "Epoch 55/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.9591 - accuracy: 0.6700\n",
      "Epoch 00055: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 21s 82ms/step - loss: 0.9591 - accuracy: 0.6700 - val_loss: 1.5425 - val_accuracy: 0.6452\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/251 [============================>.] - ETA: 0s - loss: 0.9419 - accuracy: 0.6755\n",
      "Epoch 00056: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 21s 85ms/step - loss: 0.9421 - accuracy: 0.6755 - val_loss: 1.5368 - val_accuracy: 0.6372\n",
      "Epoch 57/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.9355 - accuracy: 0.6697\n",
      "Epoch 00057: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 21s 82ms/step - loss: 0.9354 - accuracy: 0.6697 - val_loss: 1.5792 - val_accuracy: 0.6407\n",
      "Epoch 58/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.9021 - accuracy: 0.6909\n",
      "Epoch 00058: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 24s 97ms/step - loss: 0.9021 - accuracy: 0.6909 - val_loss: 1.5153 - val_accuracy: 0.6442\n",
      "Epoch 59/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.8918 - accuracy: 0.6971\n",
      "Epoch 00059: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 20s 79ms/step - loss: 0.8916 - accuracy: 0.6971 - val_loss: 1.5472 - val_accuracy: 0.6462\n",
      "Epoch 60/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.9094 - accuracy: 0.6851\n",
      "Epoch 00060: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 23s 92ms/step - loss: 0.9094 - accuracy: 0.6851 - val_loss: 1.5257 - val_accuracy: 0.6492\n",
      "Epoch 61/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.8970 - accuracy: 0.6880\n",
      "Epoch 00061: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 22s 88ms/step - loss: 0.8970 - accuracy: 0.6880 - val_loss: 1.5352 - val_accuracy: 0.6562\n",
      "Epoch 62/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.8353 - accuracy: 0.7114\n",
      "Epoch 00062: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 28s 110ms/step - loss: 0.8353 - accuracy: 0.7114 - val_loss: 1.5865 - val_accuracy: 0.6552\n",
      "Epoch 63/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.8335 - accuracy: 0.7088\n",
      "Epoch 00063: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 24s 94ms/step - loss: 0.8335 - accuracy: 0.7086 - val_loss: 1.5941 - val_accuracy: 0.6412\n",
      "Epoch 64/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.8582 - accuracy: 0.7015\n",
      "Epoch 00064: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 21s 85ms/step - loss: 0.8580 - accuracy: 0.7016 - val_loss: 1.5954 - val_accuracy: 0.6552\n",
      "Epoch 65/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.7998 - accuracy: 0.7180\n",
      "Epoch 00065: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 19s 76ms/step - loss: 0.7995 - accuracy: 0.7181 - val_loss: 1.5996 - val_accuracy: 0.6577\n",
      "Epoch 66/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.7935 - accuracy: 0.7219\n",
      "Epoch 00066: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 19s 75ms/step - loss: 0.7934 - accuracy: 0.7219 - val_loss: 1.7087 - val_accuracy: 0.6577\n",
      "Epoch 67/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.7785 - accuracy: 0.7297\n",
      "Epoch 00067: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 19s 75ms/step - loss: 0.7784 - accuracy: 0.7299 - val_loss: 1.7313 - val_accuracy: 0.6537\n",
      "Epoch 68/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.7697 - accuracy: 0.7333\n",
      "Epoch 00068: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 18s 73ms/step - loss: 0.7700 - accuracy: 0.7332 - val_loss: 1.8027 - val_accuracy: 0.6482\n",
      "Epoch 69/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.7926 - accuracy: 0.7265\n",
      "Epoch 00069: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 19s 74ms/step - loss: 0.7925 - accuracy: 0.7266 - val_loss: 1.6838 - val_accuracy: 0.6637\n",
      "Epoch 70/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.8141 - accuracy: 0.7212\n",
      "Epoch 00070: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 19s 77ms/step - loss: 0.8142 - accuracy: 0.7212 - val_loss: 1.6375 - val_accuracy: 0.6767\n",
      "Epoch 71/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.7679 - accuracy: 0.7275\n",
      "Epoch 00071: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 32s 128ms/step - loss: 0.7677 - accuracy: 0.7276 - val_loss: 1.6890 - val_accuracy: 0.6627\n",
      "Epoch 72/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.7083 - accuracy: 0.7500\n",
      "Epoch 00072: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 28s 111ms/step - loss: 0.7083 - accuracy: 0.7500 - val_loss: 1.7264 - val_accuracy: 0.6687\n",
      "Epoch 73/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.7220 - accuracy: 0.7395\n",
      "Epoch 00073: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 24s 95ms/step - loss: 0.7222 - accuracy: 0.7393 - val_loss: 1.6969 - val_accuracy: 0.6757\n",
      "Epoch 74/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.6987 - accuracy: 0.7492\n",
      "Epoch 00074: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 20s 81ms/step - loss: 0.6987 - accuracy: 0.7492 - val_loss: 1.6964 - val_accuracy: 0.6647\n",
      "Epoch 75/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.7563 - accuracy: 0.7337\n",
      "Epoch 00075: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 23s 94ms/step - loss: 0.7563 - accuracy: 0.7337 - val_loss: 1.7757 - val_accuracy: 0.6692\n",
      "Epoch 76/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.6768 - accuracy: 0.7559\n",
      "Epoch 00076: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.6766 - accuracy: 0.7558 - val_loss: 1.7114 - val_accuracy: 0.6737\n",
      "Epoch 77/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.7036 - accuracy: 0.7529\n",
      "Epoch 00077: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 24s 95ms/step - loss: 0.7035 - accuracy: 0.7530 - val_loss: 1.8412 - val_accuracy: 0.6662\n",
      "Epoch 78/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.6714 - accuracy: 0.7633\n",
      "Epoch 00078: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 28s 110ms/step - loss: 0.6714 - accuracy: 0.7633 - val_loss: 1.9566 - val_accuracy: 0.6612\n",
      "Epoch 79/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.6922 - accuracy: 0.7523\n",
      "Epoch 00079: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 30s 121ms/step - loss: 0.6922 - accuracy: 0.7523 - val_loss: 1.7092 - val_accuracy: 0.6752\n",
      "Epoch 80/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.6590 - accuracy: 0.7690\n",
      "Epoch 00080: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 28s 112ms/step - loss: 0.6589 - accuracy: 0.7690 - val_loss: 1.8503 - val_accuracy: 0.6887\n",
      "Epoch 81/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.6538 - accuracy: 0.7717\n",
      "Epoch 00081: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 26s 105ms/step - loss: 0.6538 - accuracy: 0.7717 - val_loss: 2.0097 - val_accuracy: 0.6662\n",
      "Epoch 82/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.6508 - accuracy: 0.7670\n",
      "Epoch 00082: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 25s 101ms/step - loss: 0.6506 - accuracy: 0.7671 - val_loss: 1.9829 - val_accuracy: 0.6762\n",
      "Epoch 83/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.6350 - accuracy: 0.7710\n",
      "Epoch 00083: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 24s 97ms/step - loss: 0.6350 - accuracy: 0.7710 - val_loss: 1.9669 - val_accuracy: 0.6752\n",
      "Epoch 84/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.6164 - accuracy: 0.7816\n",
      "Epoch 00084: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 24s 95ms/step - loss: 0.6164 - accuracy: 0.7816 - val_loss: 2.0317 - val_accuracy: 0.6737\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/251 [============================>.] - ETA: 0s - loss: 0.6162 - accuracy: 0.7835\n",
      "Epoch 00085: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 24s 94ms/step - loss: 0.6160 - accuracy: 0.7836 - val_loss: 1.9181 - val_accuracy: 0.6812\n",
      "Epoch 86/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.6228 - accuracy: 0.7818\n",
      "Epoch 00086: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 23s 92ms/step - loss: 0.6228 - accuracy: 0.7817 - val_loss: 1.9226 - val_accuracy: 0.6847\n",
      "Epoch 87/100\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.6602 - accuracy: 0.7672\n",
      "Epoch 00087: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 20s 82ms/step - loss: 0.6602 - accuracy: 0.7672 - val_loss: 1.9660 - val_accuracy: 0.6807\n",
      "Epoch 88/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.6757 - accuracy: 0.7626\n",
      "Epoch 00088: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 21s 83ms/step - loss: 0.6760 - accuracy: 0.7626 - val_loss: 1.9864 - val_accuracy: 0.6827\n",
      "Epoch 89/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.5945 - accuracy: 0.7884\n",
      "Epoch 00089: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 27s 107ms/step - loss: 0.5950 - accuracy: 0.7883 - val_loss: 1.8583 - val_accuracy: 0.6892\n",
      "Epoch 90/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.5702 - accuracy: 0.7943\n",
      "Epoch 00090: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 25s 101ms/step - loss: 0.5702 - accuracy: 0.7943 - val_loss: 2.1014 - val_accuracy: 0.6702\n",
      "Epoch 91/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.5755 - accuracy: 0.7925\n",
      "Epoch 00091: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 21s 82ms/step - loss: 0.5754 - accuracy: 0.7926 - val_loss: 1.9565 - val_accuracy: 0.6892\n",
      "Epoch 92/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.5894 - accuracy: 0.7887\n",
      "Epoch 00092: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 20s 79ms/step - loss: 0.5898 - accuracy: 0.7886 - val_loss: 1.9644 - val_accuracy: 0.6797\n",
      "Epoch 93/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.6069 - accuracy: 0.7861\n",
      "Epoch 00093: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 24s 97ms/step - loss: 0.6070 - accuracy: 0.7861 - val_loss: 2.0686 - val_accuracy: 0.6767\n",
      "Epoch 94/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.5742 - accuracy: 0.7959\n",
      "Epoch 00094: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 25s 101ms/step - loss: 0.5741 - accuracy: 0.7958 - val_loss: 2.0083 - val_accuracy: 0.6842\n",
      "Epoch 95/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.5382 - accuracy: 0.8127\n",
      "Epoch 00095: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 19s 77ms/step - loss: 0.5383 - accuracy: 0.8127 - val_loss: 2.0642 - val_accuracy: 0.6872\n",
      "Epoch 96/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.5419 - accuracy: 0.8071\n",
      "Epoch 00096: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 19s 74ms/step - loss: 0.5418 - accuracy: 0.8072 - val_loss: 2.2727 - val_accuracy: 0.6767\n",
      "Epoch 97/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.5199 - accuracy: 0.8156\n",
      "Epoch 00097: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 19s 76ms/step - loss: 0.5198 - accuracy: 0.8157 - val_loss: 2.0867 - val_accuracy: 0.6832\n",
      "Epoch 98/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.5532 - accuracy: 0.8104\n",
      "Epoch 00098: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 20s 78ms/step - loss: 0.5536 - accuracy: 0.8102 - val_loss: 2.0325 - val_accuracy: 0.6792\n",
      "Epoch 99/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.5622 - accuracy: 0.8019\n",
      "Epoch 00099: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 19s 75ms/step - loss: 0.5621 - accuracy: 0.8019 - val_loss: 2.2159 - val_accuracy: 0.6847\n",
      "Epoch 100/100\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.5539 - accuracy: 0.7997\n",
      "Epoch 00100: val_loss did not improve from 1.39536\n",
      "251/251 [==============================] - 18s 74ms/step - loss: 0.5538 - accuracy: 0.7998 - val_loss: 2.2374 - val_accuracy: 0.6802\n"
     ]
    }
   ],
   "source": [
    "filename = 'model.h5'\n",
    "checkpoint = ModelCheckpoint(filename,\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             mode='min')\n",
    "\n",
    "hist = model_lstm.fit(train_X, train_Y,\n",
    "                 epochs = 100,\n",
    "                 batch_size = 32,\n",
    "                 validation_data = (val_X, val_Y),\n",
    "                 callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YjXKos8ocXvw"
   },
   "outputs": [],
   "source": [
    " model_lstm = load_model(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qSTEzrlzcuya"
   },
   "outputs": [],
   "source": [
    "def predictions(text):\n",
    "  clean = re.sub(r'[^ a-z A-Z 0-9]', \" \", text)\n",
    "  test_word = word_tokenize(clean)\n",
    "  test_word = [w.lower() for w in test_word]\n",
    "  test_ls = word_tokenizer.texts_to_sequences(test_word)\n",
    "  print(test_word)\n",
    "\n",
    "  #Check for unknown words\n",
    "  if [] in test_ls:\n",
    "    test_ls = list(filter(None, test_ls))\n",
    "    \n",
    "  test_ls = np.array(test_ls).reshape(1, len(test_ls))\n",
    "  x = padding_doc(test_ls, max_length)\n",
    "\n",
    "  pred = model_lstm.predict(x)\n",
    "  \n",
    "  return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P1ddofshmdzK"
   },
   "outputs": [],
   "source": [
    "def get_final_output(pred, classes):\n",
    "  predictions = pred[0]\n",
    " \n",
    "  classes = np.array(classes)\n",
    "  ids = np.argsort(-predictions)\n",
    "  classes = classes[ids]\n",
    "  predictions = -np.sort(-predictions)\n",
    " \n",
    "  for i in range(pred.shape[1]):\n",
    "    print(\"%s has confidence = %s\" % (classes[i], (predictions[i])))\n",
    "  \n",
    "  return classes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "23VpGuihMdEU",
    "outputId": "cd36c932-0fb0-4166-92ae-546a7676e645"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'am', 'still', 'waiting', 'on', 'my', 'card']\n",
      "reverted_card_payment? has confidence = 0.18450873\n",
      "card_arrival has confidence = 0.15817639\n",
      "card_linking has confidence = 0.12097399\n",
      "card_delivery_estimate has confidence = 0.1064741\n",
      "compromised_card has confidence = 0.10200037\n",
      "declined_card_payment has confidence = 0.05154416\n",
      "lost_or_stolen_card has confidence = 0.049066834\n",
      "transaction_charged_twice has confidence = 0.047501627\n",
      "card_payment_not_recognised has confidence = 0.036972415\n",
      "cash_withdrawal_not_recognised has confidence = 0.031303987\n",
      "request_refund has confidence = 0.031057216\n",
      "card_not_working has confidence = 0.021079693\n",
      "pending_card_payment has confidence = 0.017942613\n",
      "contactless_not_working has confidence = 0.008497491\n",
      "pending_top_up has confidence = 0.008054751\n",
      "Refund_not_showing_up has confidence = 0.004341421\n",
      "balance_not_updated_after_bank_transfer has confidence = 0.004288543\n",
      "transfer_not_received_by_recipient has confidence = 0.0033927432\n",
      "balance_not_updated_after_cheque_or_cash_deposit has confidence = 0.0032268025\n",
      "top_up_failed has confidence = 0.0023433683\n",
      "direct_debit_payment_not_recognised has confidence = 0.0016651306\n",
      "cancel_transfer has confidence = 0.0014712141\n",
      "activate_my_card has confidence = 0.0010279266\n",
      "topping_up_by_card has confidence = 0.0007325939\n",
      "top_up_reverted has confidence = 0.00067024364\n",
      "card_about_to_expire has confidence = 0.00033075683\n",
      "extra_charge_on_statement has confidence = 0.00031525167\n",
      "pending_transfer has confidence = 0.00025376843\n",
      "card_payment_fee_charged has confidence = 0.0001694441\n",
      "pending_cash_withdrawal has confidence = 0.00014266488\n",
      "lost_or_stolen_phone has confidence = 7.8762685e-05\n",
      "verify_top_up has confidence = 7.581609e-05\n",
      "passcode_forgotten has confidence = 6.5786066e-05\n",
      "declined_cash_withdrawal has confidence = 4.742262e-05\n",
      "wrong_amount_of_cash_received has confidence = 3.7077963e-05\n",
      "transfer_fee_charged has confidence = 3.382713e-05\n",
      "declined_transfer has confidence = 3.2562737e-05\n",
      "pin_blocked has confidence = 2.2621058e-05\n",
      "visa_or_mastercard has confidence = 2.0943935e-05\n",
      "card_payment_wrong_exchange_rate has confidence = 1.3264364e-05\n",
      "top_up_limits has confidence = 9.551276e-06\n",
      "supported_cards_and_currencies has confidence = 7.5661947e-06\n",
      "card_swallowed has confidence = 7.277046e-06\n",
      "failed_transfer has confidence = 5.235689e-06\n",
      "card_acceptance has confidence = 2.6937528e-06\n",
      "edit_personal_details has confidence = 2.064899e-06\n",
      "transfer_timing has confidence = 1.7648853e-06\n",
      "unable_to_verify_identity has confidence = 1.7274397e-06\n",
      "beneficiary_not_allowed has confidence = 1.691029e-06\n",
      "apple_pay_or_google_pay has confidence = 1.5878446e-06\n",
      "terminate_account has confidence = 1.5112169e-06\n",
      "top_up_by_cash_or_cheque has confidence = 1.1815072e-06\n",
      "wrong_exchange_rate_for_cash_withdrawal has confidence = 5.2487746e-07\n",
      "top_up_by_card_charge has confidence = 4.5812382e-07\n",
      "country_support has confidence = 1.3935404e-07\n",
      "age_limit has confidence = 1.14556514e-07\n",
      "cash_withdrawal_charge has confidence = 1.0017262e-07\n",
      "get_physical_card has confidence = 9.34654e-08\n",
      "virtual_card_not_working has confidence = 6.933581e-08\n",
      "getting_spare_card has confidence = 5.927304e-08\n",
      "order_physical_card has confidence = 5.1681667e-08\n",
      "why_verify_identity has confidence = 5.0734858e-08\n",
      "receiving_money has confidence = 2.6826314e-08\n",
      "verify_source_of_funds has confidence = 2.2387393e-08\n",
      "transfer_into_account has confidence = 4.5445026e-09\n",
      "atm_support has confidence = 3.5053285e-09\n",
      "automatic_top_up has confidence = 3.34655e-09\n",
      "change_pin has confidence = 9.565742e-10\n",
      "top_up_by_bank_transfer_charge has confidence = 5.0569987e-10\n",
      "category has confidence = 2.7366087e-10\n",
      "getting_virtual_card has confidence = 1.4772895e-10\n",
      "exchange_charge has confidence = 1.4481581e-10\n",
      "disposable_card_limits has confidence = 3.252561e-11\n",
      "exchange_rate has confidence = 1.6944534e-11\n",
      "get_disposable_virtual_card has confidence = 4.0523717e-12\n",
      "verify_my_identity has confidence = 2.6752528e-12\n",
      "fiat_currency_support has confidence = 5.7656343e-13\n",
      "exchange_via_app has confidence = 3.2046e-13\n",
      "\n",
      "ans: reverted_card_payment?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = \"I am still waiting on my card?\"\n",
    "pred = predictions(text)\n",
    "result = get_final_output(pred, unique_intent)\n",
    "print('\\nans: {}\\n'.format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what', 'are', 'you', 'exchange', 'rates']\n",
      "exchange_rate has confidence = 0.9521722\n",
      "fiat_currency_support has confidence = 0.018024959\n",
      "exchange_via_app has confidence = 0.017376026\n",
      "exchange_charge has confidence = 0.008700637\n",
      "supported_cards_and_currencies has confidence = 0.0014381895\n",
      "card_payment_wrong_exchange_rate has confidence = 0.001223994\n",
      "wrong_exchange_rate_for_cash_withdrawal has confidence = 0.0008252348\n",
      "apple_pay_or_google_pay has confidence = 0.00023869329\n",
      "receiving_money has confidence = 2.8229067e-08\n",
      "top_up_by_card_charge has confidence = 9.1513563e-10\n",
      "direct_debit_payment_not_recognised has confidence = 5.412927e-10\n",
      "card_acceptance has confidence = 3.9122233e-10\n",
      "top_up_by_bank_transfer_charge has confidence = 2.2138892e-10\n",
      "transfer_fee_charged has confidence = 1.8366568e-10\n",
      "beneficiary_not_allowed has confidence = 1.04932375e-10\n",
      "declined_card_payment has confidence = 4.518701e-11\n",
      "reverted_card_payment? has confidence = 1.4193713e-11\n",
      "card_payment_not_recognised has confidence = 7.695896e-12\n",
      "atm_support has confidence = 4.113498e-12\n",
      "card_payment_fee_charged has confidence = 1.9096842e-12\n",
      "cash_withdrawal_charge has confidence = 1.277137e-12\n",
      "country_support has confidence = 1.1317267e-12\n",
      "top_up_limits has confidence = 7.407987e-13\n",
      "automatic_top_up has confidence = 2.682995e-13\n",
      "topping_up_by_card has confidence = 1.1231161e-13\n",
      "card_swallowed has confidence = 9.672674e-14\n",
      "compromised_card has confidence = 6.466508e-15\n",
      "cash_withdrawal_not_recognised has confidence = 4.2964145e-15\n",
      "card_about_to_expire has confidence = 4.2348903e-15\n",
      "top_up_by_cash_or_cheque has confidence = 1.2877509e-15\n",
      "transfer_into_account has confidence = 1.0762436e-15\n",
      "top_up_failed has confidence = 6.723896e-16\n",
      "declined_cash_withdrawal has confidence = 3.7613324e-16\n",
      "top_up_reverted has confidence = 1.9517779e-16\n",
      "card_not_working has confidence = 1.5230702e-16\n",
      "age_limit has confidence = 7.8826474e-17\n",
      "transaction_charged_twice has confidence = 6.1763366e-17\n",
      "contactless_not_working has confidence = 5.338938e-17\n",
      "wrong_amount_of_cash_received has confidence = 1.5566206e-17\n",
      "pending_card_payment has confidence = 4.016779e-18\n",
      "failed_transfer has confidence = 2.9752628e-18\n",
      "getting_spare_card has confidence = 8.919671e-19\n",
      "card_delivery_estimate has confidence = 4.7047846e-19\n",
      "verify_source_of_funds has confidence = 7.792048e-20\n",
      "extra_charge_on_statement has confidence = 4.580394e-20\n",
      "terminate_account has confidence = 1.9782868e-20\n",
      "request_refund has confidence = 1.3820522e-20\n",
      "lost_or_stolen_card has confidence = 2.338311e-21\n",
      "verify_top_up has confidence = 1.9709038e-21\n",
      "pending_top_up has confidence = 1.843937e-21\n",
      "order_physical_card has confidence = 5.3454255e-22\n",
      "card_arrival has confidence = 2.0773493e-22\n",
      "pending_cash_withdrawal has confidence = 1.3181637e-22\n",
      "cancel_transfer has confidence = 2.3067847e-24\n",
      "transfer_not_received_by_recipient has confidence = 1.2134126e-24\n",
      "activate_my_card has confidence = 9.3400373e-26\n",
      "declined_transfer has confidence = 5.8877675e-26\n",
      "card_linking has confidence = 1.73983e-26\n",
      "pin_blocked has confidence = 1.5728249e-26\n",
      "unable_to_verify_identity has confidence = 2.7691884e-27\n",
      "why_verify_identity has confidence = 1.5621092e-27\n",
      "pending_transfer has confidence = 1.0675882e-28\n",
      "visa_or_mastercard has confidence = 2.0461423e-29\n",
      "category has confidence = 2.4084525e-30\n",
      "balance_not_updated_after_bank_transfer has confidence = 3.7176817e-31\n",
      "transfer_timing has confidence = 5.131509e-32\n",
      "disposable_card_limits has confidence = 4.3428116e-32\n",
      "verify_my_identity has confidence = 2.568251e-35\n",
      "get_disposable_virtual_card has confidence = 2.266958e-35\n",
      "lost_or_stolen_phone has confidence = 1.287394e-35\n",
      "virtual_card_not_working has confidence = 9.0411614e-38\n",
      "get_physical_card has confidence = 0.0\n",
      "getting_virtual_card has confidence = 0.0\n",
      "edit_personal_details has confidence = 0.0\n",
      "Refund_not_showing_up has confidence = 0.0\n",
      "passcode_forgotten has confidence = 0.0\n",
      "balance_not_updated_after_cheque_or_cash_deposit has confidence = 0.0\n",
      "change_pin has confidence = 0.0\n",
      "\n",
      "ans: exchange_rate\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = \"What are you exchange rates?\"\n",
    "pred = predictions(text)\n",
    "result = get_final_output(pred, unique_intent)\n",
    "print('\\nans: {}\\n'.format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['which', 'countries', 'are', 'represented']\n",
      "country_support has confidence = 0.40900862\n",
      "fiat_currency_support has confidence = 0.21668743\n",
      "card_acceptance has confidence = 0.083111525\n",
      "supported_cards_and_currencies has confidence = 0.06816458\n",
      "getting_spare_card has confidence = 0.053985287\n",
      "atm_support has confidence = 0.04560661\n",
      "order_physical_card has confidence = 0.04163523\n",
      "exchange_via_app has confidence = 0.019778987\n",
      "card_about_to_expire has confidence = 0.01835203\n",
      "age_limit has confidence = 0.009834507\n",
      "receiving_money has confidence = 0.008849052\n",
      "card_delivery_estimate has confidence = 0.004631613\n",
      "top_up_by_card_charge has confidence = 0.0040301057\n",
      "compromised_card has confidence = 0.0023763773\n",
      "card_not_working has confidence = 0.001980662\n",
      "card_payment_fee_charged has confidence = 0.0015887762\n",
      "activate_my_card has confidence = 0.0014576323\n",
      "disposable_card_limits has confidence = 0.001454433\n",
      "exchange_rate has confidence = 0.0011822341\n",
      "lost_or_stolen_card has confidence = 0.0010140196\n",
      "visa_or_mastercard has confidence = 0.0008381222\n",
      "card_arrival has confidence = 0.0006780747\n",
      "terminate_account has confidence = 0.0006775246\n",
      "get_disposable_virtual_card has confidence = 0.000465579\n",
      "card_linking has confidence = 0.00038589464\n",
      "verify_source_of_funds has confidence = 0.00036793854\n",
      "card_swallowed has confidence = 0.00030168338\n",
      "topping_up_by_card has confidence = 0.00027173458\n",
      "pin_blocked has confidence = 0.00018961306\n",
      "exchange_charge has confidence = 0.00017695097\n",
      "top_up_by_cash_or_cheque has confidence = 0.00017318357\n",
      "transfer_into_account has confidence = 0.00013858912\n",
      "top_up_limits has confidence = 0.0001343612\n",
      "top_up_by_bank_transfer_charge has confidence = 0.00010686608\n",
      "verify_top_up has confidence = 6.671558e-05\n",
      "contactless_not_working has confidence = 6.445362e-05\n",
      "automatic_top_up has confidence = 6.400799e-05\n",
      "apple_pay_or_google_pay has confidence = 3.932909e-05\n",
      "virtual_card_not_working has confidence = 3.697887e-05\n",
      "getting_virtual_card has confidence = 3.365783e-05\n",
      "declined_card_payment has confidence = 2.7065107e-05\n",
      "reverted_card_payment? has confidence = 1.7504552e-05\n",
      "declined_cash_withdrawal has confidence = 7.463368e-06\n",
      "why_verify_identity has confidence = 2.4997935e-06\n",
      "transaction_charged_twice has confidence = 1.3058165e-06\n",
      "transfer_fee_charged has confidence = 9.0900323e-07\n",
      "request_refund has confidence = 8.7911747e-07\n",
      "get_physical_card has confidence = 5.894303e-07\n",
      "verify_my_identity has confidence = 2.3125166e-07\n",
      "top_up_failed has confidence = 1.2750947e-07\n",
      "transfer_timing has confidence = 8.6914184e-08\n",
      "card_payment_not_recognised has confidence = 8.17943e-08\n",
      "category has confidence = 7.283099e-08\n",
      "direct_debit_payment_not_recognised has confidence = 4.954824e-08\n",
      "edit_personal_details has confidence = 4.720177e-08\n",
      "cash_withdrawal_not_recognised has confidence = 1.8368498e-08\n",
      "lost_or_stolen_phone has confidence = 1.6912239e-08\n",
      "beneficiary_not_allowed has confidence = 1.5800603e-08\n",
      "change_pin has confidence = 1.3319637e-08\n",
      "unable_to_verify_identity has confidence = 1.0165063e-08\n",
      "wrong_exchange_rate_for_cash_withdrawal has confidence = 5.0885043e-09\n",
      "pending_top_up has confidence = 2.368248e-09\n",
      "wrong_amount_of_cash_received has confidence = 9.399134e-10\n",
      "balance_not_updated_after_bank_transfer has confidence = 4.2335166e-10\n",
      "top_up_reverted has confidence = 2.592017e-10\n",
      "cash_withdrawal_charge has confidence = 1.6687729e-10\n",
      "passcode_forgotten has confidence = 1.4617142e-10\n",
      "failed_transfer has confidence = 1.4010458e-10\n",
      "declined_transfer has confidence = 3.5461915e-11\n",
      "cancel_transfer has confidence = 3.0194052e-11\n",
      "card_payment_wrong_exchange_rate has confidence = 2.0527226e-11\n",
      "extra_charge_on_statement has confidence = 4.192666e-12\n",
      "pending_card_payment has confidence = 1.1055137e-12\n",
      "transfer_not_received_by_recipient has confidence = 1.2168023e-13\n",
      "pending_transfer has confidence = 1.1544019e-15\n",
      "balance_not_updated_after_cheque_or_cash_deposit has confidence = 8.8591806e-16\n",
      "Refund_not_showing_up has confidence = 2.1942902e-16\n",
      "pending_cash_withdrawal has confidence = 1.652574e-18\n",
      "\n",
      "ans: country_support\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = \"Which countries are represented?\"\n",
    "pred = predictions(text)\n",
    "result = get_final_output(pred, unique_intent)\n",
    "print('\\nans: {}\\n'.format(result))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Intent_classification_final.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bitf6eaa932bd364e6c99622ad728a40cf7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
